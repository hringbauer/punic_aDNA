{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Eigenstrat files to run PCA with HO SNPs\n",
    "Extract and Merge in relevant populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-229.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pops(df, string, col=\"clst\", \n",
    "                output=False):\n",
    "    \"\"\"Return list of clusters that contain string.\"\"\"\n",
    "    df1 = df[df[col].str.contains(string)]\n",
    "    if output:\n",
    "        print(df1[col].value_counts())\n",
    "    clsts = list(set(df1[col].values))\n",
    "    print(f\"Found #clsts labels containing {string}: {len(clsts)}\")\n",
    "\n",
    "    return clsts\n",
    "\n",
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the .ind File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46354 Individuals\n"
     ]
    }
   ],
   "source": [
    "vrs = \"54.1\"\n",
    "v0 = vrs.split(\".\")[0]\n",
    "\n",
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/v{vrs}_HO_all\"\n",
    "\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>sex</th>\n",
       "      <th>clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12344</th>\n",
       "      <td>I11059</td>\n",
       "      <td>M</td>\n",
       "      <td>Spain_C_oSteppe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33974</th>\n",
       "      <td>I0257</td>\n",
       "      <td>M</td>\n",
       "      <td>Spain_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33975</th>\n",
       "      <td>I0258</td>\n",
       "      <td>F</td>\n",
       "      <td>Spain_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33976</th>\n",
       "      <td>I0260</td>\n",
       "      <td>F</td>\n",
       "      <td>Spain_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33977</th>\n",
       "      <td>I0261</td>\n",
       "      <td>M</td>\n",
       "      <td>Spain_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38968</th>\n",
       "      <td>I31806</td>\n",
       "      <td>M</td>\n",
       "      <td>Spain_Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38972</th>\n",
       "      <td>I31805</td>\n",
       "      <td>M</td>\n",
       "      <td>Spain_Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38974</th>\n",
       "      <td>I31971</td>\n",
       "      <td>F</td>\n",
       "      <td>Spain_Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38975</th>\n",
       "      <td>I31804</td>\n",
       "      <td>F</td>\n",
       "      <td>Spain_Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38978</th>\n",
       "      <td>I31968</td>\n",
       "      <td>F</td>\n",
       "      <td>Spain_Christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          iid sex             clst\n",
       "12344  I11059   M  Spain_C_oSteppe\n",
       "33974   I0257   M          Spain_C\n",
       "33975   I0258   F          Spain_C\n",
       "33976   I0260   F          Spain_C\n",
       "33977   I0261   M          Spain_C\n",
       "...       ...  ..              ...\n",
       "38968  I31806   M  Spain_Christian\n",
       "38972  I31805   M  Spain_Christian\n",
       "38974  I31971   F  Spain_Christian\n",
       "38975  I31804   F  Spain_Christian\n",
       "38978  I31968   F  Spain_Christian\n",
       "\n",
       "[224 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Spain_C\")]\n",
    "#df_ind[df_ind[\"iid\"].str.contains(\"I15940\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definie what target populations to pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ancients\n",
    "Make sure all cluster labels have at least one match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found #clsts labels containing Algeria: 6\n",
      "Found #clsts labels containing Morocco: 8\n",
      "Found #clsts labels containing Tunisia: 22\n",
      "Found #clsts labels containing Punic: 58\n",
      "Found #clsts labels containing Phoenician: 10\n",
      "Found #clsts labels containing Spain_Vandal: 5\n",
      "Found #clsts labels containing Spain_LBA: 15\n",
      "Found #clsts labels containing Spain_Punic: 24\n",
      "Found #clsts labels containing Sardinia: 82\n",
      "Found #clsts labels containing Ibiza: 1\n",
      "Found #clsts labels containing Israel_MLBA: 12\n",
      "Found #clsts labels containing Israel_LBA: 6\n",
      "Found #clsts labels containing Israel_IA: 7\n",
      "Found #clsts labels containing Israel_LIA: 1\n",
      "Found #clsts labels containing Ashkelon: 4\n",
      "Found #clsts labels containing Sicily: 87\n",
      "Found #clsts labels containing Hellenistic: 35\n",
      "Found #clsts labels containing Israel_IA: 7\n",
      "Found #clsts labels containing Israel_EIA: 1\n",
      "Found #clsts labels containing Israel_Persian: 1\n",
      "Found #clsts labels containing Gibraltar: 2\n",
      "Found #clsts labels containing Lebanon: 19\n",
      "Found #clsts labels containing Spain_EBA_Africa: 2\n",
      "Found #clsts labels containing Spain_BellBeaker_oAfrica: 1\n",
      "Found #clsts labels containing Spain_Greek: 3\n",
      "Found #clsts labels containing Spain_Hellenistic: 4\n",
      "Found #clsts labels containing Spain_IA: 17\n",
      "Found #clsts labels containing Italy_Sardinia_N_oAfrica: 2\n",
      "Found #clsts labels containing Nigeria_IA: 2\n",
      "Found #clsts labels containing Nigeria_Medieval: 3\n",
      "Found #clsts labels containing Mallorca: 1\n",
      "Found #clsts labels containing Menorca: 4\n",
      "Found #clsts labels containing Egypt_Hellenistic: 5\n",
      "Found #clsts labels containing Egypt_Roman: 3\n",
      "Found #clsts labels containing Egypt_Dynastic: 5\n",
      "Found #clsts labels containing Egypt_Third: 3\n",
      "Found #clsts labels containing Spain_Roman_oAfrica2: 1\n",
      "Found #clsts labels containing Greece_: 62\n",
      "Found #clsts labels containing Guanche: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pops = [\"Algeria\", \"Morocco\", \"Tunisia\", \"Punic\", \"Phoenician\", \"Spain_Vandal\", \"Spain_LBA\",\n",
    "        \"Spain_Punic\", \"Sardinia\", \"Ibiza\", \"Israel_MLBA\", \"Israel_LBA\", \"Israel_IA\", \"Israel_LIA\", \n",
    "        \"Ashkelon\", \"Sicily\", \"Hellenistic\",\n",
    "        \"Israel_IA\", \"Israel_EIA\", \"Israel_Persian\", \"Gibraltar\", \"Lebanon\",\n",
    "        \"Spain_EBA_Africa\", \"Spain_BellBeaker_oAfrica\", \"Spain_Greek\",\n",
    "        \"Spain_Hellenistic\", \"Spain_IA\", \"Italy_Sardinia_N_oAfrica\", \n",
    "        \"Nigeria_IA\", \"Nigeria_Medieval\", \"Mallorca\", \"Menorca\", \n",
    "        \"Egypt_Hellenistic\", \"Egypt_Roman\", \"Egypt_Dynastic\", \"Egypt_Third\",\n",
    "        \"Spain_Roman_oAfrica2\",\n",
    "        \"Greece_\", \"Guanche\"]\n",
    "\n",
    "clsts = [return_pops(df_ind, string=pop, \n",
    "                     output=False) for pop in pops]\n",
    "\n",
    "clsts = [inner for ls in clsts for inner in ls]\n",
    "len(clsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderns\n",
    "Get list of Human Origin Populations to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1196 PCA Individuals\n",
      "Found 1196/1196 matching indivdiuals in .ind file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ho = \"/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/construct_WE_NA_PCA.v48.2.list\" # Changed some HO labels \n",
    "\n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns=[\"iid\", \"pop\"]\n",
    "print(f\"Loaded {len(df_ho)} PCA Individuals\")\n",
    "\n",
    "df_ho[\"iid\"] = df_ho[\"iid\"] + \".HO\" # Hack from v53.1 upward\n",
    "df2 = pd.merge(df_ho, df_ind, on=\"iid\")\n",
    "print(f\"Found {len(df2)}/{len(df_ho)} matching indivdiuals in .ind file\")\n",
    "assert(len(df2)==len(df_ho))\n",
    "\n",
    "clsts1 = set(df2[\"clst\"])\n",
    "#clsts1 = [p.rsplit(\"_\", 1)[0] for p in pops]\n",
    "l = [np.sum(df_ind[\"clst\"].str.contains(p)) for p in clsts1]\n",
    "assert(np.min(l)>0)\n",
    "len(clsts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>sex</th>\n",
       "      <th>clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>SAH27.HO</td>\n",
       "      <td>F</td>\n",
       "      <td>Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>SAH21.HO</td>\n",
       "      <td>F</td>\n",
       "      <td>Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>SAH24.HO</td>\n",
       "      <td>F</td>\n",
       "      <td>Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>SAH34.HO</td>\n",
       "      <td>F</td>\n",
       "      <td>Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>SAH18.HO</td>\n",
       "      <td>F</td>\n",
       "      <td>Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>SAH9.HO</td>\n",
       "      <td>F</td>\n",
       "      <td>Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>SAH20.HO</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Saharawi.HO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32932</th>\n",
       "      <td>S_Saharawi-1.DG</td>\n",
       "      <td>M</td>\n",
       "      <td>Saharawi.DG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32933</th>\n",
       "      <td>S_Saharawi-2.DG</td>\n",
       "      <td>M</td>\n",
       "      <td>Saharawi.DG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   iid sex                clst\n",
       "6177          SAH27.HO   F         Saharawi.HO\n",
       "6200          SAH21.HO   F         Saharawi.HO\n",
       "6206          SAH24.HO   F         Saharawi.HO\n",
       "6215          SAH34.HO   F         Saharawi.HO\n",
       "6235          SAH18.HO   F         Saharawi.HO\n",
       "6253           SAH9.HO   F         Saharawi.HO\n",
       "6267          SAH20.HO   M  Ignore_Saharawi.HO\n",
       "32932  S_Saharawi-1.DG   M         Saharawi.DG\n",
       "32933  S_Saharawi-2.DG   M         Saharawi.DG"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Saharawi\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and save final pop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 423 Populations\n",
      "After Exclusion 423 populations\n"
     ]
    }
   ],
   "source": [
    "exclude_strings = [\"_lc\", \"contam\"] # \"_d\"\n",
    "\n",
    "clsts = list(set(clsts).union(set(clsts1))) # Filter to unique Elements\n",
    "print(f\"Loaded {len(clsts)} Populations\")\n",
    "\n",
    "### Exclude Strings\n",
    "for ex in exclude_strings:\n",
    "    clsts = [c for c in clsts if ex not in c]\n",
    "print(f\"After Exclusion {len(clsts)} populations\")\n",
    "clsts = clsts + [\"include\"]\n",
    "clsts = list(set(clsts)) # To be unique for sure\n",
    "### Originally Loaded 379 Populations\n",
    "# After Exclusion 289 populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 423 population names to ./parfiles/pca/keep_pops.v54.1\n"
     ]
    }
   ],
   "source": [
    "keep = np.array(clsts)\n",
    "path_keep = f\"./parfiles/pca/keep_pops.v{vrs}\" # keep_pops for Kerkouane\n",
    "np.savetxt(path_keep, keep, fmt=\"%s\")\n",
    "print(f\"Saved {len(keep)} population names to {path_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .ind file with flagged out pop names\n",
    "Idea: Some individuals should not be included in the final .ind file. To do this,\n",
    "I create a .ind file where the population of these is set to \"Ignore1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /n/groups/reich/hringbauer/Data/v54.1.flagged.ind\n"
     ]
    }
   ],
   "source": [
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/v{vrs}_HO_all\" # Copy of HO Base Path Above!\n",
    "save_path = f\"/n/groups/reich/hringbauer/Data/v{vrs}.flagged.ind\"\n",
    "\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "# Exclude downsampled Indivdiuals:\n",
    "#idx = df_ind[\"iid\"].str.endswith(\"_d\")\n",
    "#df_ind.loc[idx, \"clst\"] = \"Ignore1\"\n",
    "#print(f\"Flagged out {np.sum(idx)}/{len(idx)} downsampled Individuals\")\n",
    "\n",
    "df_ind.to_csv(save_path, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include Individuals from Ilan's List and Sample List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including 110/155 IIDs from external source\n",
      "Filtered to 184/188 not exclude\n",
      "Found 180/188 IIDs from external source. Including...\n",
      "Missing...:\n",
      "['I11896_d' 'I7162_all' 'S28626.Y1.E2.L1' 'S28627.Y1.E2.L1']\n",
      "Including 180/188 IIDs from external source\n",
      "Saved to: /n/groups/reich/hringbauer/Data/v54.1.flagged.included.ind\n"
     ]
    }
   ],
   "source": [
    "save_path2 = f\"/n/groups/reich/hringbauer/Data/v{vrs}.flagged.included.ind\"\n",
    "\n",
    "df_add = pd.read_csv(\"./data/v49-added-samples.txt\", header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_add.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "df_ind = pd.read_csv(save_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "### Add the additional Indivudals\n",
    "add_inds = [\"RISE507.508.merge.SG\", \"I13517_d\", \"I13518_d\", \"I13519_d\"] # Renamed indivdual plus some Myceneans\n",
    "search_inds = np.concatenate((df_add[\"iid\"], add_inds))\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(search_inds)\n",
    "print(f\"Including {np.sum(idx)}/{len(search_inds)} IIDs from external source\")\n",
    "df_ind.loc[idx, \"clst\"] = \"include\"\n",
    "\n",
    "### Include Individuals from Sample List (see google sheets)\n",
    "df1 = pd.read_csv(\"./data/sample_list.tsv\", sep=\"\\t\")\n",
    "dft = df1[df1[\"suggested Group ID (Ilan)\"]!=\"Exclude\"]\n",
    "print(f\"Filtered to {len(dft)}/{len(df1)} not exclude\")\n",
    "iids = dft[\"Version ID\"].values\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(iids)\n",
    "print(f\"Found {np.sum(idx)}/{len(df1)} IIDs from external source. Including...\")\n",
    "print(f\"Missing...:\")\n",
    "idx1 = np.array([iid in df_ind[\"iid\"].values for iid in iids])\n",
    "print(iids[~idx1])\n",
    "### Sanity Check whether everything of Ilan found\n",
    "#assert(np.sum(idx)==len(dft)) # To make sure all indivduals found\n",
    "\n",
    "print(f\"Including {np.sum(idx)}/{len(df1)} IIDs from external source\")\n",
    "df_ind.loc[idx, \"clst\"] = \"include\"\n",
    "\n",
    "df_ind.to_csv(save_path2, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved to: {save_path2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run convertf\n",
    "Takes about 10 min for all individuals\n",
    "\n",
    "IMPORTANT: Change all required additional parameters in manually encoded parfile!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE:       /n/groups/reich/  \n",
      "DIR:\t\tDAVID/V54/V54.1/v54.1_HO_all\n",
      "OUT:        hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO\n",
      "genotypename:\tBASE/DIR.geno\n",
      "snpname:\tBASE/DIR.snp\n",
      "indivname:\t/n/groups/reich/hringbauer/Data/v54.1.flagged.included.ind\n",
      "genooutfilename:   BASE/OUT.geno\n",
      "snpoutfilename:    BASE/OUT.snp\n",
      "indoutfilename:    BASE/OUT.ind\n",
      "outputformat:   PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: BASE/hringbauer/git/punic_aDNA/parfiles/pca/keep_pops.v54.1\n"
     ]
    }
   ],
   "source": [
    "### Sanity Check whether update done correctly!\n",
    "command = f\"cat /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/convertf.keep.v{vrs}.par\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/pca/convertf.keep.v54.1.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V54/V54.1/v54.1_HO_all\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO\n",
      "genotypename: /n/groups/reich//DAVID/V54/V54.1/v54.1_HO_all.geno\n",
      "snpname: /n/groups/reich//DAVID/V54/V54.1/v54.1_HO_all.snp\n",
      "indivname: /n/groups/reich/hringbauer/Data/v54.1.flagged.included.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/pca/keep_pops.v54.1\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 8150\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5368709120 bytes\n",
      "read 6442450944 bytes\n",
      "read 6925273497 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 597573 indivs: 46354\n",
      "after compress: snps: 597573 indivs: 2571\n",
      "numvalidind:   2571  maxmiss: 2571001\n",
      "callng outfiles\n",
      "numsnps output: 597573\n",
      "##end of convertf:      994.560 seconds cpu      387.232 Mbytes in use\n",
      "CPU times: user 23.6 s, sys: 4.84 s, total: 28.4 s\n",
      "Wall time: 16min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = f\"./parfiles/pca/convertf.keep.v{vrs}.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA: Modify the .ind file to have one population to project on in moderns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1196/2571 HO individuals\n",
      "Saved 2571 overall individuals to /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.pca.ind\n",
      "1196/2571 IIDs of Alissas _mod pops set to construct_WE_NA_PCA\n"
     ]
    }
   ],
   "source": [
    "path_ind = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v{vrs}_HO.ind\"\n",
    "path_mod = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v{vrs}_HO.pca.ind\"\n",
    "\n",
    "df_ind = pd.read_csv(path_ind, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ind.columns = [\"iid\", \"sex\", \"pop\"]\n",
    "iids = df_ho[\"iid\"].values # Alissas original IIDs\n",
    "idx = [iid in iids for iid in df_ind[\"iid\"]]\n",
    "print(f\"Found {np.sum(idx)}/{len(idx)} HO individuals\")\n",
    "assert(np.sum(idx)==1196) # Sanity Check whether correct Individuals included for PCA!\n",
    "\n",
    "df_ind.loc[idx, \"pop\"]  = \"construct_WE_NA_PCA\" #df_ind.loc[idx, \"pop\"] + \"_mod\" \n",
    "df_ind.to_csv(path_mod, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} overall individuals to {path_mod}\")\n",
    "\n",
    "### Sanity Check \n",
    "#idx = [p in pops for p in df_ind[\"pop\"]] \n",
    "idx = [(p==\"construct_WE_NA_PCA\") for p in df_ind[\"pop\"]] \n",
    "print(f\"{np.sum(idx)}/{len(idx)} IIDs of Alissas _mod pops set to construct_WE_NA_PCA\")\n",
    "# in v45: 1196/2169 \n",
    "# in v49.2: 1187/2373\n",
    "# in v54.1: 1196/2571 again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"pop\"].str.contains(\"Tunisia\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1187/1196 of Alissas _mod pops\n"
     ]
    }
   ],
   "source": [
    "### Needed only for trouble shooting ###\n",
    "found = [iid in df_ind[\"iid\"].values for iid in df_ho[\"iid\"].values]\n",
    "print(f\"Found {np.sum(found)}/{len(found)} of Alissas _mod pops\")\n",
    "#df_ho[~np.array(found)][\"pop\"].value_counts() # Only for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[~np.array(found)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After saving all files: sbatch the PCA script.\n",
    "Takes about 9h for 1000 extra samples\n",
    "\n",
    "1) Manually update`./parfiles/pca/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE:\t\t   20221108\n",
      "BUILD:\t\t   construct_WE_NA_PCA\n",
      "BASE:          /n/groups/reich/hringbauer/git/punic_aDNA\n",
      "INDIR:         BASE/eigenstrat/\n",
      "GENO:          punic.v54.1_HO\n",
      "OUTDIR:        BASE/output/pca/v54.1\n",
      "genotypename:  INDIR/GENO.geno\n",
      "snpname:       INDIR/GENO.snp\n",
      "indivname:     INDIR/GENO.pca.ind \n",
      "evecoutname:   OUTDIR/DATE.GENO.BUILD.smYES.outitY.evec.txt\n",
      "evaloutname:   OUTDIR/DATE.GENO.BUILD.smYES.outitY.eval.txt\n",
      "snpweightoutname: OUTDIR/DATE.GENO.BUILD.smYES.outitY.weights.txt\n",
      "poplistname:   BASE/parfiles/pca/BUILD\n",
      "lsqproject: YES\n",
      "shrinkmode:  YES\n",
      "hiprecision: YES\n",
      "numoutevec: 4\n",
      "hashcheck: NO\n",
      "topright:  Georgian\n"
     ]
    }
   ],
   "source": [
    "command = f\"cat /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/run_WE_NA_PCA.v{vrs}.par\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Update command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --partition=priority\n",
      "#SBATCH -t 20:00:00\t\t# Time in HH:MM:SS\n",
      "#SBATCH -c 1                    # Number of cores requested\n",
      "#SBATCH -N 1                    # Ensure that all cores are on one machine (span[hosts=1])\n",
      "#SBATCH --mem=60G               # Memory total in GB (see also --mem-per-cpu)\n",
      "#SBATCH --output=/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/logs/%A_%a.out\n",
      "#SBATCH --error=/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/logs/%A_%a.err\n",
      "\n",
      "##### N&I NAGIC #####\n",
      "LD_LIBRARY_PATH=/opt/lsf/7.0/linux2.6-glibc2.3-x86_64/lib:/opt/nag/libC/lib:/usr/lib\n",
      "NAG_KUSARI_FILE=/opt/nag/nag.license\n",
      "LM_LICENSE_FILE=/opt/nag/license.dat\n",
      "\n",
      "module load gcc\n",
      "module load gsl/2.3\n",
      "module load openblas\n",
      "#module load R\n",
      "module load graphviz\n",
      "#module load matlab\n",
      "module load fftw\n",
      "\n",
      "PATH=\"$PATH:~np29/o2bin\"\n",
      "PATH=\"$PATH:/n/groups/reich/iosif/sw/fs-2.0.7\"\n",
      "PATH=\"$PATH:/n/groups/reich/iosif/sw/msdir/msdir\"\n",
      "\n",
      "##### PARAMS #####\n",
      "TDIR=\"/n/scratch2/am483\"\n",
      "PFILE=\"/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/run_WE_NA_PCA.v54.1.par\"\n",
      "\n",
      "##### ACTION #####\n",
      "~np29/o2bin/smartpca -p $PFILE\n"
     ]
    }
   ],
   "source": [
    "command = f\"cat /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/run_WE_NA_PCA.par.sh\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 64596451\n"
     ]
    }
   ],
   "source": [
    "command = f\"sbatch /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/run_WE_NA_PCA.par.sh\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           7026920  priority jupyter_     hr97  R    3:07:51      1 compute-e-16-233\n",
      "           7042789  priority run_WE_N     hr97  R      14:13      1 compute-a-16-38\n"
     ]
    }
   ],
   "source": [
    "!squeue -u hr97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Meta File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v46.3.anno.csv\")\n",
    "path_ho = \"/n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v46.3.share.ind\"\n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns = [\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "df_save = pd.merge(df_ho[\"iid\"], df_meta, on=\"iid\")\n",
    "df_save = df_save.sort_values(by=\"clst\")\n",
    "#df_save.to_csv(\"./data/meta/v46.3_punic_meta.tsv\", sep=\"\\t\", index=False)\n",
    "df_save.to_csv(\"./output/share/v46.3_punic_meta.share.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
