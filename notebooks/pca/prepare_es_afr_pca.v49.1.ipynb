{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Files for qpAdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "# For Arial Font\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'   # Set the defaul\n",
    "# Make sure to have the font installed (it is on cluster for Harald)\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./explore_ntbk/parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile\n",
    "    \n",
    "def return_pops(df, string, col=\"clst\", \n",
    "                output=False):\n",
    "    \"\"\"Return list of clusters that contain string.\"\"\"\n",
    "    df1 = df[df[col].str.contains(string)]\n",
    "    if output:\n",
    "        print(df1[col].value_counts())\n",
    "    clsts = list(set(df1[col].values))\n",
    "    print(f\"Found #clsts labels containing {string}: {len(clsts)}\")\n",
    "    return clsts\n",
    "\n",
    "def extract_df_countries(df, countries, age_col=\"\", \n",
    "                         snp_col=\"\", min_snps=0):\n",
    "    \"\"\"Extract Individuals from list of countries\"\"\"\n",
    "    age = pd.to_numeric(df[age_col], errors=\"coerce\")\n",
    "    snps = pd.to_numeric(df[snp_col], errors=\"coerce\")\n",
    "    if min_snps>0:\n",
    "        idx0 = snps>=min_snps\n",
    "    else:\n",
    "        idx0 = np.ones(len(df), dtype=\"bool\")\n",
    "    \n",
    "    for c in countries:\n",
    "        idx = df[\"Country\"].isin([c])\n",
    "        idxb = idx & idx0\n",
    "        print(f\"{c}: {np.sum(idxb)}/{np.sum(idx)} inds\")\n",
    "\n",
    "    idx = (df[\"Country\"].isin(countries)) & idx0\n",
    "    print(f\"Returning {np.sum(idx)} Indivdiual Dataframe\")\n",
    "    return df[idx]\n",
    "\n",
    "def extract_subset_df(df, countries, n_per_c=50):\n",
    "    \"\"\"Extract subset of n_per_c random samples per country in list.\n",
    "    Return dataframe\"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    for c in countries:\n",
    "        idx = (df[\"Country\"]==c)\n",
    "        dft = df[idx]\n",
    "        if len(dft)>n_per_c:\n",
    "            dft = dft.sample(n=n_per_c, replace=False)\n",
    "        dfs.append(dft.copy())\n",
    "        \n",
    "    df = pd.concat(dfs)\n",
    "    print(f\"Subset to: {len(df)} Individuals\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Ind File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 37020 Individuals\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/n/groups/reich/DAVID/V49/V49.1/v49.1_HO\"\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")\n",
    "\n",
    "df_anno = pd.read_csv(base_path + \".anno\", sep=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_anno[df_anno[\"Country\"].str.contains(\"Egypt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract based on Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morocco: 83/83 inds\n",
      "Algeria: 70/70 inds\n",
      "Tunisia: 53/53 inds\n",
      "Libya: 15/15 inds\n",
      "Egypt: 74/74 inds\n",
      "Sudan: 352/352 inds\n",
      "Eritrea: 4/4 inds\n",
      "Chad: 5/5 inds\n",
      "Niger: 10/10 inds\n",
      "Nigeria: 706/706 inds\n",
      "Burkina Faso: 31/31 inds\n",
      "Mali: 1/1 inds\n",
      "Senegal: 70/70 inds\n",
      "Mauritania: 0/0 inds\n",
      "Canary Islands: 5/5 inds\n",
      "Gambia: 121/121 inds\n",
      "Jordan: 71/71 inds\n",
      "Sierra Leone: 95/95 inds\n",
      "Returning 1766 Indivdiual Dataframe\n",
      "Found 1766/1766 North African  IIDs from Meta\n",
      "Extracting 266 Group Labels\n"
     ]
    }
   ],
   "source": [
    "### Extract all modern samples:\n",
    "df_afr = extract_df_countries(df_anno, \n",
    "                              countries = [\"Morocco\", \"Algeria\", \"Tunisia\", \"Libya\", \"Egypt\", \"Sudan\", \"Eritrea\", \"Chad\", \n",
    "                                           \"Niger\", \"Nigeria\", \"Burkina Faso\", \"Mali\", \"Senegal\", \n",
    "                                           \"Mauritania\", \"Canary Islands\", \"Gambia\", \"Jordan\", \"Sierra Leone\"],\n",
    "                              age_col = 'Date mean in BP [OxCal mu for a direct radiocarbon date, and average of range for a contextual date]',\n",
    "                              snp_col = \"Coverage on autosomal targets\")\n",
    "\n",
    "iids_meta = df_afr[\"Version ID\"].values\n",
    "idx = [iid in iids_meta for iid in df_ind[\"iid\"]]\n",
    "print(f\"Found {np.sum(idx)}/{len(df_afr)} North African  IIDs from Meta\")\n",
    "clsts_countries = set(df_ind[\"clst\"][idx])\n",
    "print(f\"Extracting {len(clsts_countries)} Group Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_afr[df_afr[\"Country\"].str.contains(\"Egypt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found #clsts labels containing Punic: 41\n",
      "Found #clsts labels containing Phoenician: 3\n",
      "Found #clsts labels containing Ibiza: 1\n",
      "Found #clsts labels containing Phoenician: 3\n",
      "Found #clsts labels containing Ashkelon: 4\n",
      "Found #clsts labels containing Spain_EBA_Africa: 3\n",
      "Found #clsts labels containing Italy_Sardinia_C_oAfrica: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pops = [\"Punic\", \"Phoenician\", \"Ibiza\", \"Phoenician\", \"Ashkelon\",\n",
    "        \"Spain_EBA_Africa\", \"Italy_Sardinia_C_oAfrica\"]\n",
    "\n",
    "exclude_strings = [\"_lc\", \"contam\"]\n",
    "\n",
    "clsts = [return_pops(df_ind, string=pop, \n",
    "                     output=False) for pop in pops]\n",
    "clsts = [inner for ls in clsts for inner in ls]\n",
    "len(clsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and save Pop List to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 313 Populations\n",
      "After Exclusion: 251 Population Labels\n"
     ]
    }
   ],
   "source": [
    "exclude_strings = [\"_lc\", \"contam\"]\n",
    "clsts1 = list(set(clsts).union(set(clsts_countries))) # Filter to unique Elements\n",
    "print(f\"Total: {len(clsts1)} Populations\")\n",
    "\n",
    "### Exclude Strings\n",
    "for ex in exclude_strings:\n",
    "    clsts1 = [c for c in clsts1 if ex not in c]\n",
    "print(f\"After Exclusion: {len(clsts1)} Population Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 251 population names to ./parfiles/pops/keep_pops_nafr\n"
     ]
    }
   ],
   "source": [
    "keep = np.array(clsts1)\n",
    "path_keep = \"./parfiles/pops/keep_pops_nafr\" # keep_pops for Kerkouane\n",
    "np.savetxt(path_keep, keep, fmt=\"%s\")\n",
    "print(f\"Saved {len(keep)} population names to {path_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Adjust Parfile here now, only then run convertf\n",
    "Takes ca. 10 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/convertf/afr.v49.1.HO.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V49/V49.1/v49.1_HO\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1\n",
      "genotypename: /n/groups/reich//DAVID/V49/V49.1/v49.1_HO.geno\n",
      "snpname: /n/groups/reich//DAVID/V49/V49.1/v49.1_HO.snp\n",
      "indivname: /n/groups/reich//DAVID/V49/V49.1/v49.1_HO.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/pops/keep_pops_nafr\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 5750\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5368709120 bytes\n",
      "read 5530538115 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 597573 indivs: 37020\n",
      "after compress: snps: 597573 indivs: 1826\n",
      "numvalidind:   1826  maxmiss: 1826001\n",
      "packedancestrymap output\n",
      "numsnps output: 597573\n",
      "##end of convertf:      496.930 seconds cpu      368.038 Mbytes in use\n",
      "CPU times: user 9.91 s, sys: 2.11 s, total: 12 s\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = \"./parfiles/convertf/afr.v49.1.HO.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify .ind file to have projection available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morocco: 59/83 inds\n",
      "Algeria: 66/70 inds\n",
      "Tunisia: 15/53 inds\n",
      "Libya: 15/15 inds\n",
      "Egypt: 22/74 inds\n",
      "Sudan: 244/352 inds\n",
      "Eritrea: 0/4 inds\n",
      "Chad: 4/5 inds\n",
      "Niger: 0/10 inds\n",
      "Nigeria: 682/706 inds\n",
      "Burkina Faso: 30/31 inds\n",
      "Mali: 0/1 inds\n",
      "Senegal: 63/70 inds\n",
      "Mauritania: 0/0 inds\n",
      "Canary Islands: 1/5 inds\n",
      "Returning 1201 Indivdiual Dataframe\n"
     ]
    }
   ],
   "source": [
    "vrs = \"49.1\"\n",
    "v0 = vrs.split(\".\")[0]\n",
    "\n",
    "path_ind = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/v{vrs}.ind\"\n",
    "path_mod = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/{vrs}_mod.ind\"\n",
    "base_path = f\"/n/groups/reich/DAVID/V49/V{vrs}/v{vrs}_HO\"\n",
    "\n",
    "df_ind = pd.read_csv(path_ind, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ind.columns = [\"iid\", \"sex\", \"pop\"]\n",
    "\n",
    "df_anno = pd.read_csv(base_path + \".anno\", sep=\"\\t\", low_memory=False)\n",
    "### Extract Individuals with sufficiently many SNPs\n",
    "df_pca = extract_df_countries(df_anno, \n",
    "                              countries = [\"Morocco\", \"Algeria\", \"Tunisia\", \"Libya\", \"Egypt\", \n",
    "                                           \"Sudan\", \"Eritrea\", \"Chad\", \n",
    "                                           \"Niger\", \"Nigeria\", \"Burkina Faso\", \"Mali\", \"Senegal\", \n",
    "                                           \"Mauritania\", \"Canary Islands\"],\n",
    "                              age_col = 'Date mean in BP [OxCal mu for a direct radiocarbon date, and average of range for a contextual date]',\n",
    "                              snp_col = \"SNPs hit on autosomal targets\", min_snps=550000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset to: 342 Individuals\n",
      "Unique Indivdiuals for PCA: 342\n"
     ]
    }
   ],
   "source": [
    "countries = [\"Morocco\", \"Algeria\", \"Tunisia\", \"Libya\", \"Egypt\", \n",
    "             \"Sudan\", \"Eritrea\", \"Chad\", \n",
    "             \"Niger\", \"Nigeria\", \"Burkina Faso\", \"Mali\", \n",
    "             \"Senegal\", \"Mauritania\", \"Canary Islands\"]\n",
    "\n",
    "### Remove Duplicates\n",
    "idx_dup = df_pca.duplicated(subset=\"Master ID\")\n",
    "df_pca = df_pca[~idx_dup].copy()\n",
    "\n",
    "df_pca1 = extract_subset_df(df_pca, countries, n_per_c=60)\n",
    "\n",
    "print(f\"Unique Indivdiuals for PCA: {len(df_pca1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 342/342 Inds for PCA. Set Pop to: construct_NAFR_PCA\n",
      "Saved 1826 overall individuals to /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/49.1_mod.ind\n"
     ]
    }
   ],
   "source": [
    "#iids_pca = df_pca1[\"Master ID\"].values\n",
    "iids_pca = df_pca1[\"Version ID\"].values\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(iids_pca)\n",
    "idx0= df_ind[\"pop\"].str.contains(\"Jew\")\n",
    "idx1= df_ind[\"iid\"].str.contains(\"Jew\")\n",
    "idx2 = (idx0 | idx1)\n",
    "\n",
    "### Set Population Label\n",
    "label_pop_pca = \"construct_NAFR_PCA\"\n",
    "df_ind.loc[idx, \"pop\"]  = label_pop_pca #df_ind.loc[idx, \"pop\"] + \"_mod\" \n",
    "\n",
    "### Sanity Check\n",
    "#idx = [(p==label_pop_pca) for p in df_ind[\"pop\"]] \n",
    "idx = df_ind[\"pop\"] == label_pop_pca\n",
    "print(f\"Found {np.sum(idx)}/{len(iids_pca)} Inds for PCA. Set Pop to: {label_pop_pca}\")\n",
    "\n",
    "df_ind.to_csv(path_mod, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} overall individuals to {path_mod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Jewish Pops to not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 Pop Jewish\n",
      "Found 23 IID Jewish\n",
      "Found 307/342 Inds for PCA. Set Pop to: construct_NAFR_PCA\n",
      "Saved 1826 overall individuals to /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1_mod2.ind\n"
     ]
    }
   ],
   "source": [
    "path_mod = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/v{vrs}_mod2.ind\"\n",
    "\n",
    "print(f\"Found {np.sum(idx0)} Pop Jewish\")\n",
    "print(f\"Found {np.sum(idx1)} IID Jewish\")\n",
    "\n",
    "df_ind1 = df_ind.copy()\n",
    "df_ind1.loc[idx2, \"pop\"]  = \"Jew\" \n",
    "idxt = df_ind1[\"pop\"]==\"construct_NAFR_PCA\"\n",
    "print(f\"Found {np.sum(idxt)}/{len(iids_pca)} Inds for PCA. Set Pop to: {label_pop_pca}\")\n",
    "\n",
    "df_ind1.to_csv(path_mod, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} overall individuals to {path_mod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you can sbatch the PCA script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 9h for 1000 extra samples\n",
    "\n",
    "See in `./parfiles/pca/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/nafr/v49.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addtional: Prepare File for sharing source Eigenstrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/convertf/afrPCApops.v49.0.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: hringbauer/git/punic_aDNA/eigenstrat/nafr/v46.3.v2\n",
      "OUT: hringbauer/git/punic_aDNA/output/share/nada.v46.3/PCApopsNAfr\n",
      "genotypename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/nafr/v46.3.v2.geno\n",
      "snpname: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/nafr/v46.3.v2.snp\n",
      "indivname: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/nafr/v46.3.v2_mod2.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/output/share/nada.v46.3/PCApopsNAfr.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/output/share/nada.v46.3/PCApopsNAfr.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/output/share/nada.v46.3/PCApopsNAfr.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/pops/keep_pops_PCA.NAfr\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 5722\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 597573 indivs: 1831\n",
      "after compress: snps: 597573 indivs: 299\n",
      "numvalidind:    299  maxmiss: 299001\n",
      "packedancestrymap output\n",
      "numsnps output: 597573\n",
      "##end of convertf:       71.660 seconds cpu      368.038 Mbytes in use\n",
      "CPU times: user 1.73 s, sys: 382 ms, total: 2.11 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = \"./parfiles/convertf/afrPCApops.v49.0.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = pd.read_csv(\"/n/groups/reich/hringbauer/git/punic_aDNA/output/share/nada.v46.3/PCApopsNAfr.ind\", \n",
    "                     header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ind.columns = [\"iid\", \"sex\", \"pop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = pd.read_csv(\"/n/groups/reich/DAVID/V46/V46.3/v46.3_HO.ind\", header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ind.columns = [\"iid\", \"sex\", \"pop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"pop\"].str.contains(\"Egypt\")][\"pop\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Egyptian1                                11\n",
       "Egyptian2                                 7\n",
       "Ignore_Egyptian_Comas(PCA_outlier)        3\n",
       "Ignore_Egyptian_Metspalu(PCA_outlier)     1\n",
       "Name: Group Label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca[df_pca[\"Group Label\"].str.contains(\"Egypt\")][\"Group Label\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
