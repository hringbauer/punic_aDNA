{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Eigenstrat files to run PCA with HO SNPs\n",
    "Extract and Merge in relevant populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-a-16-64.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 32\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pops(df, string, col=\"clst\", \n",
    "                output=False):\n",
    "    \"\"\"Return list of clusters that contain string.\"\"\"\n",
    "    df1 = df[df[col].str.contains(string)]\n",
    "    if output:\n",
    "        print(df1[col].value_counts())\n",
    "    clsts = list(set(df1[col].values))\n",
    "    print(f\"Found #clsts labels containing {string}: {len(clsts)}\")\n",
    "\n",
    "    return clsts\n",
    "\n",
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the .ind File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34764 Individuals\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/n/groups/reich/DAVID/V46/V46.3/v46.3_HO\"\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if everything loaded\n",
    "return_pops(df_ind, \"Russia_Greek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Lebanon\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definie what target populations to pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ancients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found #clsts labels containing Algeria: 5\n",
      "Found #clsts labels containing Morocco: 8\n",
      "Found #clsts labels containing Tunisia: 10\n",
      "Found #clsts labels containing Punic: 38\n",
      "Found #clsts labels containing Phoenician: 3\n",
      "Found #clsts labels containing Spain_Vandal: 4\n",
      "Found #clsts labels containing Spain_LBA: 5\n",
      "Found #clsts labels containing Sardinia: 69\n",
      "Found #clsts labels containing Ibiza: 1\n",
      "Found #clsts labels containing Israel_MLBA: 12\n",
      "Found #clsts labels containing Israel_LBA: 2\n",
      "Found #clsts labels containing Ashkelon: 4\n",
      "Found #clsts labels containing Sicily: 73\n",
      "Found #clsts labels containing Hellenistic: 32\n",
      "Found #clsts labels containing Israel_IA: 3\n",
      "Found #clsts labels containing Israel_EIA: 1\n",
      "Found #clsts labels containing Israel_Persian: 1\n",
      "Found #clsts labels containing Gibraltar: 2\n",
      "Found #clsts labels containing Lebanon: 15\n",
      "Found #clsts labels containing Spain_EBA_Afric: 3\n",
      "Found #clsts labels containing Spain_BellBeaker_oAfrican: 2\n",
      "Found #clsts labels containing Spain_Greek: 3\n",
      "Found #clsts labels containing Spain_Hellenistic: 4\n",
      "Found #clsts labels containing Spain_IA: 18\n",
      "Found #clsts labels containing Italy_Sardinia_C_oAfrican: 2\n",
      "Found #clsts labels containing Nigeria_IA: 1\n",
      "Found #clsts labels containing Nigeria_Medieval: 2\n",
      "Found #clsts labels containing Mallorca: 1\n",
      "Found #clsts labels containing Menorca: 3\n",
      "Found #clsts labels containing Egypt_Hellenistic: 5\n",
      "Found #clsts labels containing Egypt_Roman: 3\n",
      "Found #clsts labels containing Egypt_Dynastic: 5\n",
      "Found #clsts labels containing Greece_: 48\n",
      "Found #clsts labels containing Russia_Greek: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pops = [\"Algeria\", \"Morocco\", \"Tunisia\", \"Punic\", \"Phoenician\", \"Spain_Vandal\", \"Spain_LBA\",\n",
    "        \"Sardinia\", \"Ibiza\", \"Israel_MLBA\", \"Israel_LBA\", \"Ashkelon\", \"Sicily\", \"Hellenistic\",\n",
    "        \"Israel_IA\", \"Israel_EIA\", \"Israel_Persian\", \"Gibraltar\", \"Lebanon\",\n",
    "        \"Spain_EBA_Afric\", \"Spain_BellBeaker_oAfrican\", \"Spain_Greek\",\n",
    "        \"Spain_Hellenistic\", \"Spain_IA\", \"Italy_Sardinia_C_oAfrican\", \n",
    "        \"Nigeria_IA\", \"Nigeria_Medieval\", \"Mallorca\", \"Menorca\", \n",
    "        \"Egypt_Hellenistic\", \"Egypt_Roman\", \"Egypt_Dynastic\",\n",
    "        \"Greece_\", \"Russia_Greek\"]\n",
    "\n",
    "exclude_strings = [\"_lc\", \"contam\"]\n",
    "\n",
    "clsts = [return_pops(df_ind, string=pop, \n",
    "                     output=False) for pop in pops]\n",
    "\n",
    "clsts = [inner for ls in clsts for inner in ls]\n",
    "len(clsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsts = [c for c in clsts if \"Tunisia_Punic\" not in c]\n",
    "len(clsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderns\n",
    "Get list of Human Origin Populations to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1196 Individuals\n"
     ]
    }
   ],
   "source": [
    "path_ho = \"/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/construct_WE_NA_PCA.list\"\n",
    "\n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns=[\"iid\", \"pop\"]\n",
    "print(f\"Loaded {len(df_ho)} Individuals\")\n",
    "\n",
    "pops = set(df_ho[\"pop\"])\n",
    "clsts1 = [p.rsplit(\"_\", 1)[0] for p in pops]\n",
    "l = [np.sum(df_ind[\"clst\"].str.contains(p)) for p in clsts1]\n",
    "assert(np.min(l)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and save final pop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 423 Populations\n",
      "After Exclusion 343 populations\n"
     ]
    }
   ],
   "source": [
    "exclude_strings = [\"_lc\", \"contam\", \"_d\"]\n",
    "\n",
    "clsts = list(set(clsts).union(set(clsts1))) # Filter to unique Elements\n",
    "print(f\"Loaded {len(clsts)} Populations\")\n",
    "\n",
    "### Exclude Strings\n",
    "for ex in exclude_strings:\n",
    "    clsts = [c for c in clsts if ex not in c]\n",
    "print(f\"After Exclusion {len(clsts)} populations\")\n",
    "\n",
    "### Originally Loaded 379 Populations\n",
    "# After Exclusion 289 populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 343 population names to ./parfiles/pca/keep_pops1\n"
     ]
    }
   ],
   "source": [
    "keep = np.array(clsts)\n",
    "path_keep = \"./parfiles/pca/keep_pops1\" # keep_pops for Kerkouane\n",
    "np.savetxt(path_keep, keep, fmt=\"%s\")\n",
    "print(f\"Saved {len(keep)} population names to {path_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run convertf\n",
    "Takes about 20 min for all individuals\n",
    "\n",
    "Check additional parameters in manually encoded parfile!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/pca/convertf.keep.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V46/V46.1/v46.1_HO\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/punic.v46_HO.share\n",
      "genotypename: /n/groups/reich//DAVID/V46/V46.1/v46.1_HO.geno\n",
      "snpname: /n/groups/reich//DAVID/V46/V46.1/v46.1_HO.snp\n",
      "indivname: /n/groups/reich//DAVID/V46/V46.1/v46.1_HO.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v46_HO.share.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v46_HO.share.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v46_HO.share.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/pca/keep_pops1\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 5722\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5193506943 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 597573 indivs: 34761\n",
      "after compress: snps: 597573 indivs: 2159\n",
      "numvalidind:   2159  maxmiss: 2159001\n",
      "packedancestrymap output\n",
      "numsnps output: 597573\n",
      "##end of convertf:     1258.630 seconds cpu      368.038 Mbytes in use\n",
      "CPU times: user 28.2 s, sys: 6.05 s, total: 34.3 s\n",
      "Wall time: 21min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = \"./parfiles/pca/convertf.keep.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the .ind file to have one population to project on in moderns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe1094634953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic1.v46_HO.share.pca.ind\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"iid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pop\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0miids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m# Alissas original IIDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "path_ind = \"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v46_HO.share.ind\"\n",
    "path_mod = \"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic1.v46_HO.share.pca.ind\"\n",
    "\n",
    "df_ind = pd.read_csv(path_ind, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ind.columns = [\"iid\", \"sex\", \"pop\"]\n",
    "iids = df_ho[\"iid\"].values # Alissas original IIDs\n",
    "idx = [iid in iids for iid in df_ind[\"iid\"]]\n",
    "print(f\"Found {np.sum(idx)}/{len(idx)} HO individuals\")\n",
    "\n",
    "df_ind.loc[idx, \"pop\"]  = \"construct_WE_NA_PCA\" #df_ind.loc[idx, \"pop\"] + \"_mod\" \n",
    "df_ind.to_csv(path_mod, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} overall individuals to {path_mod}\")\n",
    "\n",
    "### Sanity Check \n",
    "#idx = [p in pops for p in df_ind[\"pop\"]] \n",
    "idx = [(p==\"construct_WE_NA_PCA\") for p in df_ind[\"pop\"]] \n",
    "print(f\"Found {np.sum(idx)}/{len(idx)} of Alissas _mod pops\")\n",
    "# in v45: 1196/2169 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind.loc[idx, \"pop\"]  = \"construct_WE_NA_PCA\" #df_ind.loc[idx, \"pop\"] + \"_mod\" \n",
    "df_ind.to_csv(path_mod, sep=\" \", index=None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1196/1196 of Alissas _mod pops\n"
     ]
    }
   ],
   "source": [
    "### Needed only for trouble shooting ###\n",
    "found = [iid in df_ind[\"iid\"].values for iid in df_ho[\"iid\"]]\n",
    "print(f\"Found {np.sum(found)}/{len(found)} of Alissas _mod pops\")\n",
    "#df_ho[~np.array(found)][\"pop\"].value_counts() # Only for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "construct_WE_NA_PCA                  1196\n",
       "Italy_Sicily_Punic                     54\n",
       "Assyrian                               47\n",
       "Israel_MLBA                            35\n",
       "Tunisia_Punic                          28\n",
       "                                     ... \n",
       "Spain_Punic_Roman_oAfrican1             1\n",
       "Israel_IA_o                             1\n",
       "Italy_Sicily_BellBeaker_published       1\n",
       "Italy_Sicily_MBA_o2                     1\n",
       "Egypt_Dynastic                          1\n",
       "Name: pop, Length: 268, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[\"pop\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"pop\"].str.contains(\"Tunisia_Ph\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now sbatch the PCA script.\n",
    "Takes about 9h for 1000 extra samples\n",
    "\n",
    "See in `./parfiles/pca/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Meta File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v46.3.anno.csv\")\n",
    "path_ho = \"/n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v46.3.share.ind\"\n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns = [\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "df_save = pd.merge(df_ho[\"iid\"], df_meta, on=\"iid\")\n",
    "df_save = df_save.sort_values(by=\"clst\")\n",
    "#df_save.to_csv(\"./data/meta/v46.3_punic_meta.tsv\", sep=\"\\t\", index=False)\n",
    "df_save.to_csv(\"./output/share/v46.3_punic_meta.share.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save[df_save[\"clst\"].str.contains(\"Tunisia\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
