{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Eigenstrat files to run PCA with HO SNPs\n",
    "Extract and Merge in relevant populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pops(df, string, col=\"clst\", \n",
    "                output=False):\n",
    "    \"\"\"Return list of clusters that contain string.\"\"\"\n",
    "    df1 = df[df[col].str.contains(string)]\n",
    "    if output:\n",
    "        print(df1[col].value_counts())\n",
    "    clsts = list(set(df1[col].values))\n",
    "    print(f\"Found #clsts labels containing {string}: {len(clsts)}\")\n",
    "\n",
    "    return clsts\n",
    "\n",
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the .ind File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40406 Individuals\n"
     ]
    }
   ],
   "source": [
    "vrs = \"51.1\"\n",
    "v0 = vrs.split(\".\")[0]\n",
    "\n",
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/HO/v{vrs}_HO\"\n",
    "\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>sex</th>\n",
       "      <th>clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>HGDP01253</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>HGDP01254</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>HGDP01255</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>HGDP01256</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>HGDP01257</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>HGDP01258</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>HGDP01259</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>HGDP01260</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>HGDP01261</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>HGDP01262</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>HGDP01263</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>HGDP01264</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>HGDP01265</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>HGDP01268</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>HGDP01269</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>HGDP01270</td>\n",
       "      <td>F</td>\n",
       "      <td>Ignore_Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>HGDP01271</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>HGDP01272</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>HGDP01273</td>\n",
       "      <td>F</td>\n",
       "      <td>Ignore_Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>HGDP01274</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>HGDP01275</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>HGDP01276</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>HGDP01277</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>HGDP01278</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>HGDP01279</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>HGDP01280</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>HGDP01282</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12705</th>\n",
       "      <td>S_Mozabite-1.DG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.DG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>S_Mozabite-2.DG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.DG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20295</th>\n",
       "      <td>HGDP01257.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20339</th>\n",
       "      <td>HGDP01256.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20358</th>\n",
       "      <td>HGDP01255.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20789</th>\n",
       "      <td>HGDP01269.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20810</th>\n",
       "      <td>HGDP01277.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20828</th>\n",
       "      <td>HGDP01268.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20847</th>\n",
       "      <td>HGDP01260.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Ignore_Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20853</th>\n",
       "      <td>HGDP01254.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20884</th>\n",
       "      <td>HGDP01270.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite_oSubSaharan.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20890</th>\n",
       "      <td>HGDP01276.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20891</th>\n",
       "      <td>HGDP01262.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20894</th>\n",
       "      <td>HGDP01282.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>HGDP01275.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20933</th>\n",
       "      <td>HGDP01271.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite_oSubSaharan.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20955</th>\n",
       "      <td>HGDP01267.SDG</td>\n",
       "      <td>U</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20964</th>\n",
       "      <td>HGDP01258.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>HGDP01280.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>HGDP01261.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite_oSubSaharan.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>HGDP01264.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20986</th>\n",
       "      <td>HGDP01259.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20990</th>\n",
       "      <td>HGDP01263.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21006</th>\n",
       "      <td>HGDP01266.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21007</th>\n",
       "      <td>HGDP01265.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21010</th>\n",
       "      <td>HGDP01272.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21011</th>\n",
       "      <td>HGDP01279.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21047</th>\n",
       "      <td>HGDP01253.SDG</td>\n",
       "      <td>M</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21061</th>\n",
       "      <td>HGDP01274.SDG</td>\n",
       "      <td>F</td>\n",
       "      <td>Mozabite.SDG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   iid sex                      clst\n",
       "4527         HGDP01253   M                  Mozabite\n",
       "4528         HGDP01254   F                  Mozabite\n",
       "4529         HGDP01255   M                  Mozabite\n",
       "4530         HGDP01256   M                  Mozabite\n",
       "4531         HGDP01257   M                  Mozabite\n",
       "4532         HGDP01258   M                  Mozabite\n",
       "4533         HGDP01259   M                  Mozabite\n",
       "4534         HGDP01260   M           Ignore_Mozabite\n",
       "4535         HGDP01261   M           Ignore_Mozabite\n",
       "4536         HGDP01262   M                  Mozabite\n",
       "4537         HGDP01263   M                  Mozabite\n",
       "4538         HGDP01264   M                  Mozabite\n",
       "4539         HGDP01265   M                  Mozabite\n",
       "4540         HGDP01268   M                  Mozabite\n",
       "4541         HGDP01269   M           Ignore_Mozabite\n",
       "4542         HGDP01270   F           Ignore_Mozabite\n",
       "4543         HGDP01271   M           Ignore_Mozabite\n",
       "4544         HGDP01272   M                  Mozabite\n",
       "4545         HGDP01273   F           Ignore_Mozabite\n",
       "4546         HGDP01274   F                  Mozabite\n",
       "4547         HGDP01275   F                  Mozabite\n",
       "4548         HGDP01276   F                  Mozabite\n",
       "4549         HGDP01277   F                  Mozabite\n",
       "4550         HGDP01278   M                  Mozabite\n",
       "4551         HGDP01279   M                  Mozabite\n",
       "4552         HGDP01280   F                  Mozabite\n",
       "4553         HGDP01282   M                  Mozabite\n",
       "12705  S_Mozabite-1.DG   M               Mozabite.DG\n",
       "12740  S_Mozabite-2.DG   F               Mozabite.DG\n",
       "20295    HGDP01257.SDG   M              Mozabite.SDG\n",
       "20339    HGDP01256.SDG   M              Mozabite.SDG\n",
       "20358    HGDP01255.SDG   M              Mozabite.SDG\n",
       "20789    HGDP01269.SDG   M       Ignore_Mozabite.SDG\n",
       "20810    HGDP01277.SDG   F              Mozabite.SDG\n",
       "20828    HGDP01268.SDG   M              Mozabite.SDG\n",
       "20847    HGDP01260.SDG   M       Ignore_Mozabite.SDG\n",
       "20853    HGDP01254.SDG   F              Mozabite.SDG\n",
       "20884    HGDP01270.SDG   F  Mozabite_oSubSaharan.SDG\n",
       "20890    HGDP01276.SDG   F              Mozabite.SDG\n",
       "20891    HGDP01262.SDG   M              Mozabite.SDG\n",
       "20894    HGDP01282.SDG   M              Mozabite.SDG\n",
       "20919    HGDP01275.SDG   F              Mozabite.SDG\n",
       "20933    HGDP01271.SDG   M  Mozabite_oSubSaharan.SDG\n",
       "20955    HGDP01267.SDG   U              Mozabite.SDG\n",
       "20964    HGDP01258.SDG   M              Mozabite.SDG\n",
       "20968    HGDP01280.SDG   F              Mozabite.SDG\n",
       "20969    HGDP01261.SDG   M  Mozabite_oSubSaharan.SDG\n",
       "20971    HGDP01264.SDG   M              Mozabite.SDG\n",
       "20986    HGDP01259.SDG   M              Mozabite.SDG\n",
       "20990    HGDP01263.SDG   M              Mozabite.SDG\n",
       "21006    HGDP01266.SDG   M              Mozabite.SDG\n",
       "21007    HGDP01265.SDG   M              Mozabite.SDG\n",
       "21010    HGDP01272.SDG   M              Mozabite.SDG\n",
       "21011    HGDP01279.SDG   M              Mozabite.SDG\n",
       "21047    HGDP01253.SDG   M              Mozabite.SDG\n",
       "21061    HGDP01274.SDG   F              Mozabite.SDG"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Mozab\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definie what target populations to pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ancients\n",
    "Make sure all cluster labels have at least one match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found #clsts labels containing Algeria: 5\n",
      "Found #clsts labels containing Morocco: 9\n",
      "Found #clsts labels containing Tunisia: 12\n",
      "Found #clsts labels containing Punic: 45\n",
      "Found #clsts labels containing Phoenician: 3\n",
      "Found #clsts labels containing Spain_Vandal: 5\n",
      "Found #clsts labels containing Spain_LBA: 9\n",
      "Found #clsts labels containing Spain_Punic: 19\n",
      "Found #clsts labels containing Sardinia: 84\n",
      "Found #clsts labels containing Ibiza: 1\n",
      "Found #clsts labels containing Israel_MLBA: 14\n",
      "Found #clsts labels containing Israel_LBA: 4\n",
      "Found #clsts labels containing Israel_IA: 7\n",
      "Found #clsts labels containing Israel_LIA: 1\n",
      "Found #clsts labels containing Ashkelon: 4\n",
      "Found #clsts labels containing Sicily: 86\n",
      "Found #clsts labels containing Hellenistic: 36\n",
      "Found #clsts labels containing Israel_IA: 7\n",
      "Found #clsts labels containing Israel_EIA: 1\n",
      "Found #clsts labels containing Israel_Persian: 1\n",
      "Found #clsts labels containing Gibraltar: 2\n",
      "Found #clsts labels containing Lebanon: 15\n",
      "Found #clsts labels containing Spain_EBA_Africa: 3\n",
      "Found #clsts labels containing Spain_BellBeaker_oAfrica: 2\n",
      "Found #clsts labels containing Spain_Greek: 3\n",
      "Found #clsts labels containing Spain_Hellenistic: 4\n",
      "Found #clsts labels containing Spain_IA: 18\n",
      "Found #clsts labels containing Italy_Sardinia_C_oAfrica: 2\n",
      "Found #clsts labels containing Nigeria_IA: 3\n",
      "Found #clsts labels containing Nigeria_Medieval: 3\n",
      "Found #clsts labels containing Mallorca: 1\n",
      "Found #clsts labels containing Menorca: 4\n",
      "Found #clsts labels containing Egypt_Hellenistic: 5\n",
      "Found #clsts labels containing Egypt_Roman: 3\n",
      "Found #clsts labels containing Egypt_Dynastic: 5\n",
      "Found #clsts labels containing Egypt_Third: 3\n",
      "Found #clsts labels containing Spain_Roman_oAfrica2: 1\n",
      "Found #clsts labels containing Greece_: 59\n",
      "Found #clsts labels containing Guanche: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pops = [\"Algeria\", \"Morocco\", \"Tunisia\", \"Punic\", \"Phoenician\", \"Spain_Vandal\", \"Spain_LBA\",\n",
    "        \"Spain_Punic\", \"Sardinia\", \"Ibiza\", \"Israel_MLBA\", \"Israel_LBA\", \"Israel_IA\", \"Israel_LIA\", \n",
    "        \"Ashkelon\", \"Sicily\", \"Hellenistic\",\n",
    "        \"Israel_IA\", \"Israel_EIA\", \"Israel_Persian\", \"Gibraltar\", \"Lebanon\",\n",
    "        \"Spain_EBA_Africa\", \"Spain_BellBeaker_oAfrica\", \"Spain_Greek\",\n",
    "        \"Spain_Hellenistic\", \"Spain_IA\", \"Italy_Sardinia_C_oAfrica\", \n",
    "        \"Nigeria_IA\", \"Nigeria_Medieval\", \"Mallorca\", \"Menorca\", \n",
    "        \"Egypt_Hellenistic\", \"Egypt_Roman\", \"Egypt_Dynastic\", \"Egypt_Third\",\n",
    "        \"Spain_Roman_oAfrica2\",\n",
    "        \"Greece_\", \"Guanche\"]\n",
    "\n",
    "clsts = [return_pops(df_ind, string=pop, \n",
    "                     output=False) for pop in pops]\n",
    "\n",
    "clsts = [inner for ls in clsts for inner in ls]\n",
    "len(clsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderns\n",
    "Get list of Human Origin Populations to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1196 Individuals\n"
     ]
    }
   ],
   "source": [
    "path_ho = \"/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/construct_WE_NA_PCA.v48.2.list\" # Changed some HO labels \n",
    "\n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns=[\"iid\", \"pop\"]\n",
    "print(f\"Loaded {len(df_ho)} Individuals\")\n",
    "\n",
    "pops = set(df_ho[\"pop\"])\n",
    "clsts1 = [p.rsplit(\"_\", 1)[0] for p in pops]\n",
    "l = [np.sum(df_ind[\"clst\"].str.contains(p)) for p in clsts1]\n",
    "assert(np.min(l)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and save final pop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 486 Populations\n",
      "After Exclusion 405 populations\n"
     ]
    }
   ],
   "source": [
    "exclude_strings = [\"_lc\", \"contam\"] # \"_d\"\n",
    "\n",
    "clsts = list(set(clsts).union(set(clsts1))) # Filter to unique Elements\n",
    "print(f\"Loaded {len(clsts)} Populations\")\n",
    "\n",
    "### Exclude Strings\n",
    "for ex in exclude_strings:\n",
    "    clsts = [c for c in clsts if ex not in c]\n",
    "print(f\"After Exclusion {len(clsts)} populations\")\n",
    "clsts = clsts + [\"include\"]\n",
    "### Originally Loaded 379 Populations\n",
    "# After Exclusion 289 populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 406 population names to ./parfiles/pca/keep_pops.v51.1\n"
     ]
    }
   ],
   "source": [
    "keep = np.array(clsts)\n",
    "path_keep = f\"./parfiles/pca/keep_pops.v{vrs}\" # keep_pops for Kerkouane\n",
    "np.savetxt(path_keep, keep, fmt=\"%s\")\n",
    "print(f\"Saved {len(keep)} population names to {path_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .ind file with flagged out pop names\n",
    "Idea: Some individuals should not be included in the final .ind file. To do this,\n",
    "I create a .ind file where the population of these is set to \"Ignore1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /n/groups/reich/hringbauer/Data/v51.1.flagged.ind\n"
     ]
    }
   ],
   "source": [
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/HO/v{vrs}_HO\"\n",
    "save_path = f\"/n/groups/reich/hringbauer/Data/v{vrs}.flagged.ind\"\n",
    "\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "# Exclude downsampled Indivdiuals:\n",
    "#idx = df_ind[\"iid\"].str.endswith(\"_d\")\n",
    "#df_ind.loc[idx, \"clst\"] = \"Ignore1\"\n",
    "#print(f\"Flagged out {np.sum(idx)}/{len(idx)} downsampled Individuals\")\n",
    "\n",
    "df_ind.to_csv(save_path, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include Individuals from Ilan's List and Sample List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including 154/155 IIDs from external source\n",
      "Filtered to 184/188 not exclude\n",
      "Including 184/188 IIDs from external source\n",
      "Saved to: /n/groups/reich/hringbauer/Data/v51.1.flagged.included.ind\n"
     ]
    }
   ],
   "source": [
    "save_path2 = f\"/n/groups/reich/hringbauer/Data/v{vrs}.flagged.included.ind\"\n",
    "\n",
    "df_add = pd.read_csv(\"./data/v49-added-samples.txt\", header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_add.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "df_ind = pd.read_csv(save_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "### Add the additional Indivudals\n",
    "add_inds = [\"RISE507.508.merge.SG\", \"I13517_d\", \"I13518_d\", \"I13519_d\"] # Renamed indivdual plus some Myceneans\n",
    "search_inds = np.concatenate((df_add[\"iid\"], add_inds))\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(search_inds)\n",
    "print(f\"Including {np.sum(idx)}/{len(search_inds)} IIDs from external source\")\n",
    "df_ind.loc[idx, \"clst\"] = \"include\"\n",
    "\n",
    "\n",
    "### Include Individuals from Sample List (see google sheets)\n",
    "df1 = pd.read_csv(\"./data/sample_list.tsv\", sep=\"\\t\")\n",
    "dft = df1[df1[\"suggested Group ID (Ilan)\"]!=\"Exclude\"]\n",
    "print(f\"Filtered to {len(dft)}/{len(df1)} not exclude\")\n",
    "iids = dft[\"Version ID\"].values\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(iids)\n",
    "assert(np.sum(idx)==len(dft)) # To make sure all indivduals found\n",
    "print(f\"Including {np.sum(idx)}/{len(df1)} IIDs from external source\")\n",
    "df_ind.loc[idx, \"clst\"] = \"include\"\n",
    "\n",
    "df_ind.to_csv(save_path2, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved to: {save_path2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run convertf\n",
    "Takes about 10 min for all individuals\n",
    "\n",
    "IMPORTANT: Change all required additional parameters in manually encoded parfile!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/pca/convertf.keep.v51.1.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V51/V51.1/HO/v51.1_HO\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/punic.v51.1_HO\n",
      "genotypename: /n/groups/reich//DAVID/V51/V51.1/HO/v51.1_HO.geno\n",
      "snpname: /n/groups/reich//DAVID/V51/V51.1/HO/v51.1_HO.snp\n",
      "indivname: /n/groups/reich/hringbauer/Data/v51.1.flagged.included.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v51.1_HO.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v51.1_HO.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/punic.v51.1_HO.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/pca/keep_pops.v51.1\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 5800\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5368709120 bytes\n",
      "read 6036682446 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 597573 indivs: 40406\n",
      "after compress: snps: 597573 indivs: 2494\n",
      "numvalidind:   2494  maxmiss: 2494001\n",
      "packedancestrymap output\n",
      "numsnps output: 597573\n",
      "##end of convertf:      690.170 seconds cpu      387.232 Mbytes in use\n",
      "CPU times: user 15.7 s, sys: 3.36 s, total: 19.1 s\n",
      "Wall time: 11min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = f\"./parfiles/pca/convertf.keep.v{vrs}.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the .ind file to have one population to project on in moderns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1187/2494 HO individuals\n",
      "Saved 2494 overall individuals to /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v51.1_HO.pca.ind\n",
      "1187/2494 IIDs of Alissas _mod pops set to construct_WE_NA_PCA\n"
     ]
    }
   ],
   "source": [
    "path_ind = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v{vrs}_HO.ind\"\n",
    "path_mod = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v{vrs}_HO.pca.ind\"\n",
    "\n",
    "df_ind = pd.read_csv(path_ind, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ind.columns = [\"iid\", \"sex\", \"pop\"]\n",
    "iids = df_ho[\"iid\"].values # Alissas original IIDs\n",
    "idx = [iid in iids for iid in df_ind[\"iid\"]]\n",
    "print(f\"Found {np.sum(idx)}/{len(idx)} HO individuals\")\n",
    "assert(np.sum(idx)==1187) # Sanity Check whether \n",
    "\n",
    "df_ind.loc[idx, \"pop\"]  = \"construct_WE_NA_PCA\" #df_ind.loc[idx, \"pop\"] + \"_mod\" \n",
    "df_ind.to_csv(path_mod, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} overall individuals to {path_mod}\")\n",
    "\n",
    "### Sanity Check \n",
    "#idx = [p in pops for p in df_ind[\"pop\"]] \n",
    "idx = [(p==\"construct_WE_NA_PCA\") for p in df_ind[\"pop\"]] \n",
    "print(f\"{np.sum(idx)}/{len(idx)} IIDs of Alissas _mod pops set to construct_WE_NA_PCA\")\n",
    "# in v49.2: 1187/2373\n",
    "# in v45: 1196/2169 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1187/1196 of Alissas _mod pops\n"
     ]
    }
   ],
   "source": [
    "### Needed only for trouble shooting ###\n",
    "found = [iid in df_ind[\"iid\"].values for iid in df_ho[\"iid\"].values]\n",
    "print(f\"Found {np.sum(found)}/{len(found)} of Alissas _mod pops\")\n",
    "#df_ho[~np.array(found)][\"pop\"].value_counts() # Only for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[~np.array(found)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now sbatch the PCA script.\n",
    "Takes about 9h for 1000 extra samples\n",
    "\n",
    "Manually do it in `./parfiles/pca/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Meta File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v46.3.anno.csv\")\n",
    "path_ho = \"/n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v46.3.share.ind\"\n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns = [\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "df_save = pd.merge(df_ho[\"iid\"], df_meta, on=\"iid\")\n",
    "df_save = df_save.sort_values(by=\"clst\")\n",
    "#df_save.to_csv(\"./data/meta/v46.3_punic_meta.tsv\", sep=\"\\t\", index=False)\n",
    "df_save.to_csv(\"./output/share/v46.3_punic_meta.share.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
