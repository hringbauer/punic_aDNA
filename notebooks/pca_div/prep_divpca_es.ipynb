{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Eigenstrat for Diversity PCA\n",
    "Includes all Samples from Sites with at least n individuals within +-300 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "\n",
    "# For Arial Font\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'   # Set the defaul\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)\n",
    "\n",
    "from python.plot_pca import *  # Import functions needed for the PCA plotting\n",
    "from hapsburg.PackagesSupport.sqrt_scale import SquareRootScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sample List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v54.1.anno.csv\") # Load Meta Data\n",
    "# v54.1 Meta uses the \"Y haplogroup  in ISOGG v15.73 notation (automatically called)\" column\n",
    "\n",
    "# Get all samples from Western Eurasia\n",
    "min_snp = 35000\n",
    "age = [0, 12000]\n",
    "lat = [20, 90]\n",
    "lon = [-28, 90]\n",
    "flag = [\"_contam\", \"_dup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering to 30288/33967 indiviuals with >35000 SNPs.\n",
      "Filtering to 23823/30288 inds >0 BP.\n",
      "Filtering to 23691/23823 inds <12000 BP.\n",
      "Kept 16982/23691 inds with matching lat/lon.\n",
      "Kept 16748/16982 inds with good cluster labels.\n",
      "Kept 15674/16748 unique Master IDs.\n",
      "Filtering to 6720/15674 published Samples\n",
      "Filtered to 2279/2829 IIDs within 300 years around median and >=10 samples\n",
      "Extracted IIDs of 157 IIDs in Punic Project\n"
     ]
    }
   ],
   "source": [
    "df_meta[\"study\"]=df_meta[\"study\"].fillna(\"missing\")\n",
    "idx = df_meta[\"n_cov_snp\"]>min_snp\n",
    "df=df_meta[idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(idx)}/{len(idx)} indiviuals with >{min_snp} SNPs.\")\n",
    "df[\"include\"]=df[\"include_alt\"].astype(\"int\")\n",
    "df_full = df.copy()\n",
    "\n",
    "### Filtering based on Age\n",
    "min_age=age[0]\n",
    "idx = df[\"age\"]>min_age\n",
    "df=df[idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(idx)}/{len(idx)} inds >{min_age} BP.\")\n",
    "\n",
    "max_age = age[1]\n",
    "idx = df[\"age\"]<max_age\n",
    "df = df[idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(idx)}/{len(idx)} inds <{max_age} BP.\")\n",
    "\n",
    "### Geographic Filtering\n",
    "if (len(lat)>0) | (len(lon)>0):\n",
    "    idx_lat = (lat[0] < df[\"lat\"]) & (df[\"lat\"] < lat[1])\n",
    "    idx_lon = (lon[0] < df[\"lon\"]) & (df[\"lon\"] < lon[1])\n",
    "    idx = (idx_lat & idx_lon)\n",
    "    df=df[idx].reset_index(drop=True)\n",
    "    print(f\"Kept {np.sum(idx)}/{len(idx)} inds with matching lat/lon.\")\n",
    "\n",
    "### Flag tricky Indivdiuals\n",
    "idx = df[\"clst\"].str.contains(\"|\".join(flag))\n",
    "print(f\"Kept {np.sum(~idx)}/{len(idx)} inds with good cluster labels.\")\n",
    "df=df[~idx].reset_index(drop=True)\n",
    "df = df.sort_values(by=\"avg_cov_snp\", ascending=False)\n",
    "idx = df[\"Master ID\"].duplicated()\n",
    "print(f\"Kept {np.sum(~idx)}/{len(idx)} unique Master IDs.\")\n",
    "df=df[~idx].reset_index(drop=True)\n",
    "\n",
    "### Filtering to published Samples\n",
    "idx = df[\"study\"].str.contains(\"Unpublished\")\n",
    "df=df[~idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(~idx)}/{len(idx)} published Samples\")\n",
    "\n",
    "\n",
    "\n",
    "### Keep only sites where enough samples are within medium Age\n",
    "def filter_df_age(df, age_delta = 300, output=False):\n",
    "    \"\"\"Takes Dataframe as Input, and filters to samples within age_delta of median age.\n",
    "    Return Dataframe and medium Age\"\"\"\n",
    "    age_med = np.median(df[\"age\"])\n",
    "    idx = (df[\"age\"]< age_med + age_delta) & (df[\"age\"] > age_med - age_delta)\n",
    "    df = df[idx].copy().reset_index(drop=False)\n",
    "    if output:\n",
    "        print(f\"{np.sum(idx)}/{len(idx)} IIDs within {age_delta} y of median age {age_med}\")\n",
    "    return df\n",
    "\n",
    "min_n = 10\n",
    "age_delta=300\n",
    "\n",
    "cts = df[\"loc\"].value_counts()\n",
    "sites = cts[cts>=min_n].index.values\n",
    "\n",
    "idx = df[\"loc\"].isin(sites)\n",
    "n = np.sum(idx)\n",
    "\n",
    "dfss = [filter_df_age(df[df[\"loc\"]==s], age_delta=age_delta) for s in sites]\n",
    "df = pd.concat(dfss)\n",
    "\n",
    "### Second Round of filtering (to ensure age gap)\n",
    "cts = df[\"loc\"].value_counts()\n",
    "sites = cts[cts>=min_n].index.values\n",
    "idx = df[\"loc\"].isin(sites)\n",
    "df = df[idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Filtered to {len(df)}/{n} IIDs within {age_delta} years around median and >={min_n} samples\")\n",
    "iids_anc = df[\"iid\"].values\n",
    "\n",
    "### Add Individuals from Punic project\n",
    "df1 = pd.read_csv(\"./data/cluster_assignments_punic.v54.1c.tsv\", sep=\"\\t\")\n",
    "iids_anc2 = df1[\"iid\"].values\n",
    "print(f\"Extracted IIDs of {len(iids_anc2)} IIDs in Punic Project\")\n",
    "# Make sure that all samples are in .ind file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Prepare HO Eigenstrat for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46354 HO Individuals\n"
     ]
    }
   ],
   "source": [
    "vrs = \"54.1\"\n",
    "v0 = vrs.split(\".\")[0]\n",
    "\n",
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/v{vrs}_HO_all\"\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} HO Individuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) HO samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1196 PCA Individuals\n",
      "Found 1196/1196 matching HO indivdiuals in .ind file\n"
     ]
    }
   ],
   "source": [
    "path_ho = \"/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/construct_WE_NA_PCA.v48.2.list\" # Changed some HO labels \n",
    "df_ho = pd.read_csv(path_ho, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_ho.columns=[\"iid\", \"pop\"]\n",
    "print(f\"Loaded {len(df_ho)} PCA Individuals\")\n",
    "\n",
    "df_ho[\"iid\"] = df_ho[\"iid\"] + \".HO\" # Hack from v53.1 upward\n",
    "df2 = pd.merge(df_ho, df_ind, on=\"iid\")\n",
    "print(f\"Found {len(df2)}/{len(df_ho)} matching HO indivdiuals in .ind file\")\n",
    "assert(len(df2)==len(df_ho))\n",
    "iids_ho = df_ho[\"iid\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an .ind file with samples to keep flagged out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_ind[\"iid\"].isin(iids_ho)\n",
    "assert(np.sum(idx)==len(iids_ho))\n",
    "df_ind.loc[idx, \"clst\"] = \"keep_ho\"\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(iids_anc) | df_ind[\"iid\"].isin(iids_anc2)\n",
    "assert(np.sum(idx)==len(iids_anc) + len(iids_anc2))\n",
    "df_ind.loc[idx, \"clst\"] = \"keep_anc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keep_anc                                  2436\n",
       "keep_ho                                   1196\n",
       "Spain_Islamic                              214\n",
       "Italy_IA                                   178\n",
       "England_EastYorkshire_MIA_LIA              163\n",
       "                                          ... \n",
       "Ignore_Dolgan.HO                             1\n",
       "Argentina_RegionalDevelopmentPeriod_lc       1\n",
       "Ignore_Tubalar_PCA_outlier.HO                1\n",
       "Ignore_Hakka_PCA_Outlier.HO                  1\n",
       "CostaRica_SapoaCeramic_1d.rel.I32144         1\n",
       "Name: clst, Length: 9617, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[\"clst\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 46354 IIDs to modified .ind file: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.pca_var.ind\n"
     ]
    }
   ],
   "source": [
    "path_mod = f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v{vrs}_HO.pca_var.ind\"\n",
    "df_ind.to_csv(path_mod, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} IIDs to modified .ind file: {path_mod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Run convertf \n",
    "Update convertf command and then run to downsample to Eigenstrat file with only IIDs in `keep_anc` and `keep_ho` pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE:       /n/groups/reich/  \n",
      "DIR:\t\tDAVID/V54/V54.1/v54.1_HO_all\n",
      "OUT:        hringbauer/git/punic_aDNA/eigenstrat/varPCA/varPCA.v54.1\n",
      "genotypename:\tBASE/DIR.geno\n",
      "snpname:\tBASE/DIR.snp\n",
      "indivname:\t/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.pca_var.ind\n",
      "genooutfilename:   BASE/OUT.geno\n",
      "snpoutfilename:    BASE/OUT.snp\n",
      "indoutfilename:    BASE/OUT.ind\n",
      "outputformat:   PACKEDANCESTRYMAP\n",
      "hashcheck: NO\n",
      "poplistname: BASE/hringbauer/git/punic_aDNA/parfiles/pca_var/keep_pops.v54.1"
     ]
    }
   ],
   "source": [
    "### Sanity Check whether update done correctly!\n",
    "command = f\"cat /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca_var/convertf.keep.v{vrs}.par\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run convertf - takes about 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/pca_var/convertf.keep.v54.1.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V54/V54.1/v54.1_HO_all\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/varPCA/varPCA.v54.1\n",
      "genotypename: /n/groups/reich//DAVID/V54/V54.1/v54.1_HO_all.geno\n",
      "snpname: /n/groups/reich//DAVID/V54/V54.1/v54.1_HO_all.snp\n",
      "indivname: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/punic.v54.1_HO.pca_var.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/varPCA/varPCA.v54.1.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/varPCA/varPCA.v54.1.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/varPCA/varPCA.v54.1.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: NO\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/pca_var/keep_pops.v54.1\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 8150\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5368709120 bytes\n",
      "read 6442450944 bytes\n",
      "read 6925273497 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 597573 indivs: 46354\n",
      "after compress: snps: 597573 indivs: 3632\n",
      "numvalidind:   3632  maxmiss: 3632001\n",
      "callng outfiles\n",
      "numsnps output: 597573\n",
      "##end of convertf:     1111.430 seconds cpu      387.232 Mbytes in use\n",
      "CPU times: user 26.3 s, sys: 5.63 s, total: 32 s\n",
      "Wall time: 18min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = f\"./parfiles/pca_var/convertf.keep.v{vrs}.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) SBATCH the PCA Script\n",
    "Takes about 9h for 1000 extra samples (here turn OFF shrink-mode for first test).\n",
    "\n",
    "Seems to finish in ca. 1h now without using shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE:\t\t   20230424\n",
      "BUILD:\t\t   construct_WE_NA_PCA\n",
      "BASE:          /n/groups/reich/hringbauer/git/punic_aDNA\n",
      "INDIR:         BASE/eigenstrat/varPCA/\n",
      "GENO:          varPCA.v54.1\n",
      "OUTDIR:        BASE/output/pca/v54.1var/\n",
      "genotypename:  INDIR/GENO.geno\n",
      "snpname:       INDIR/GENO.snp\n",
      "indivname:     INDIR/GENO.ind \n",
      "evecoutname:   OUTDIR/DATE.GENO.BUILD.smYES.outitY.evec.txt\n",
      "evaloutname:   OUTDIR/DATE.GENO.BUILD.smYES.outitY.eval.txt\n",
      "snpweightoutname: OUTDIR/DATE.GENO.BUILD.smYES.outitY.weights.txt\n",
      "poplistname:   BASE/parfiles/pca_var/BUILD\n",
      "lsqproject: YES\n",
      "shrinkmode:  NO\n",
      "hiprecision: YES\n",
      "numoutevec: 4\n",
      "numoutlieriter: 4\n",
      "hashcheck: NO\n",
      "topright:  Georgian\n"
     ]
    }
   ],
   "source": [
    "command = f\"cat /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca_var/run_WE_NA_PCA.v{vrs}.par\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --partition=priority\n",
      "#SBATCH -t 10:00:00\t\t# Time in HH:MM:SS\n",
      "#SBATCH -c 1                    # Number of cores requested\n",
      "#SBATCH -N 1                    # Ensure that all cores are on one machine (span[hosts=1])\n",
      "#SBATCH --mem=60G               # Memory total in GB (see also --mem-per-cpu)\n",
      "#SBATCH --output=/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/logs/%A_%a.out\n",
      "#SBATCH --error=/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca/logs/%A_%a.err\n",
      "\n",
      "##### N&I NAGIC #####\n",
      "LD_LIBRARY_PATH=/opt/lsf/7.0/linux2.6-glibc2.3-x86_64/lib:/opt/nag/libC/lib:/usr/lib\n",
      "NAG_KUSARI_FILE=/opt/nag/nag.license\n",
      "LM_LICENSE_FILE=/opt/nag/license.dat\n",
      "\n",
      "module load gcc\n",
      "module load gsl/2.3\n",
      "module load openblas\n",
      "#module load R\n",
      "module load graphviz\n",
      "#module load matlab\n",
      "module load fftw\n",
      "\n",
      "PATH=\"$PATH:~np29/o2bin\"\n",
      "PATH=\"$PATH:/n/groups/reich/iosif/sw/fs-2.0.7\"\n",
      "PATH=\"$PATH:/n/groups/reich/iosif/sw/msdir/msdir\"\n",
      "\n",
      "##### PARAMS #####\n",
      "TDIR=\"/n/scratch2/am483\"\n",
      "PFILE=\"/n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca_var/run_WE_NA_PCA.v54.1.par\"\n",
      "\n",
      "##### ACTION #####\n",
      "~np29/o2bin/smartpca -p $PFILE\n"
     ]
    }
   ],
   "source": [
    "command = f\"cat /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca_var/run_WE_NA_PCA.par.sh\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 7266382\n"
     ]
    }
   ],
   "source": [
    "command = f\"sbatch /n/groups/reich/hringbauer/git/punic_aDNA/parfiles/pca_var/run_WE_NA_PCA.par.sh\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           7258129  priority jupyter_     hr97  R    5:42:01      1 compute-e-16-233\n",
      "           7266382  priority run_WE_N     hr97  R       0:14      1 compute-e-16-230\n"
     ]
    }
   ],
   "source": [
    "!squeue -u hr97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
