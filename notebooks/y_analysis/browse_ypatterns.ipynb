{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to plot Y chromosome diversity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-235.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# For Arial Font\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'   # Set the defaul\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "from matplotlib import gridspec\n",
    "#plt.style.use('ggplot') #..../whitegrid.mplstyle  # Nice Plotting Style\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)\n",
    "\n",
    "from python.plot_pca import *  # Import functions needed for the PCA plotting\n",
    "from hapsburg.PackagesSupport.sqrt_scale import SquareRootScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_df_age(df, age_delta = 300, output=False):\n",
    "    \"\"\"Takes Dataframe df as Input, and filters to samples within age_delta of median age.\n",
    "    Return filtered Dataframe and medium Age\"\"\"\n",
    "    age_med = np.median(df[\"age\"])\n",
    "    idx = (df[\"age\"]< age_med + age_delta) & (df[\"age\"] > age_med - age_delta)\n",
    "    df = df[idx].copy().reset_index(drop=False)\n",
    "    if output:\n",
    "        print(f\"{np.sum(idx)}/{len(idx)} IIDs within {age_delta} y of median age {age_med}\")\n",
    "    return df, age_med\n",
    "\n",
    "def get_y_counts(df, digits=3, col=\"Y_haplo\"):\n",
    "    \"\"\"Get Y Chromosome counts from Dataframe df\"\"\"\n",
    "    ys = df[col].str[:3]\n",
    "    cts = ys.value_counts().values\n",
    "    return cts\n",
    "\n",
    "def simpson_di(x):\n",
    "    \"\"\" Given a count vector, returns the Simpson Diversity Index\n",
    "    \"\"\"\n",
    "    n = np.sum(x) # Sample Size\n",
    "    h = np.sum(x*(x-1)) / (n*(n-1)) # Fraction of pairs are identiclal\n",
    "    \n",
    "    if h==0: ### Set minimimum homo-cutoff (one homo-pair):\n",
    "        h = 2 / (n*(n-1))\n",
    "    return 1 / h\n",
    "\n",
    "def frac_max_haplo(x):\n",
    "    \"\"\"Given a count vector, return frequency of non most-common alleles\"\"\"\n",
    "    f = np.max(x) / np.sum(x)\n",
    "    return f\n",
    "\n",
    "def create_ydiv_df(df, sites=[], col_loc=\"loc\", method=\"simpson\",\n",
    "                   age_delta = 300, digits=3, min_m=5):\n",
    "    \"\"\"Take Meta Data as input, and for each site calculate\n",
    "    the Simpson Index of Y chromosomes.\n",
    "    method: simpson, frac_max_haplo\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for s in sites:\n",
    "        df_t = df[df[col_loc]==s]\n",
    "        df_t, age = filter_df_age(df_t, age_delta=age_delta)\n",
    "        m = len(df_t)\n",
    "        \n",
    "        if m >= min_m: # Only run full analysis if enough males\n",
    "            y = get_y_counts(df_t)\n",
    "            if method==\"simpson\":\n",
    "                D = simpson_di(y)\n",
    "            elif method==\"frac_max_haplo\":\n",
    "                D = frac_max_haplo(y)\n",
    "            else:\n",
    "                raise RuntimeWarning(\"No fitting mode found.\")\n",
    "            data.append([s, age, m, D])\n",
    "          \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [\"loc\", \"age\", \"males\", \"D\"]\n",
    "    return df\n",
    "\n",
    "def get_sub_df_region(df, region=\"\", rec_col=\"region\", loc_col=\"loc\", min_n=5):\n",
    "    \"\"\"Get a Dataframe of Y haplogroup diversities per sites\"\"\"\n",
    "    df_ib = df[df[rec_col].isin(region)]\n",
    "    cts = df_ib[loc_col].value_counts()\n",
    "    sites = cts[cts>=min_n].index.values\n",
    "    df_y_it = create_ydiv_df(df, sites=sites)\n",
    "    return df_y_it\n",
    "\n",
    "def set_age_ydiv_df(df, site=\"\", age=0,\n",
    "                    site_col=\"loc\", age_col=\"age\"):\n",
    "    \"\"\"Set the Age of a Y Diversity Cluster\"\"\"\n",
    "    idx = df[site_col]==site\n",
    "    df.loc[idx, age_col]= age\n",
    "\n",
    "def set_legends(ax, plots=[], legs=[], title=\"\", loc=\"lower right\"):\n",
    "    \"\"\"Set Legends in Panel Plots\"\"\"\n",
    "    l1 = ax.legend(plots, legs, fontsize=11, loc=loc,\n",
    "             title=title)\n",
    "    \n",
    "    l1.get_title().set_fontsize('13')\n",
    "    l1.get_title().set_fontweight(\"bold\")\n",
    "    [lgd.set_color('white') for lgd in l1.legendHandles]\n",
    "    [lgd.set_edgecolor('k') for lgd in l1.legendHandles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Meta and Y haplogroup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering to 29227/35545 indiviuals with >100000 SNPs.\n",
      "Filtering to 22574/29227 inds >0 BP.\n",
      "Filtering to 22448/22574 inds <12000 BP.\n",
      "Kept 17910/22448 inds with matching lat/lon.\n",
      "Kept 17707/17910 inds with good cluster labels.\n",
      "Kept 16715/17707 unique Master IDs.\n",
      "Kept 9262/16715 Males.\n",
      "Extracted IIDs of 160 IIDs in Punic Project\n",
      "Merged to 68 Punic Males\n",
      "Filtered to 58 Punic Samples based on label\n",
      "Filtered general Y to 9194 ancient, non Punic individuals\n",
      "Filtered to 4059 published ancient males\n"
     ]
    }
   ],
   "source": [
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v56.3.anno.haplogroups.csv\") # Load Meta Data\n",
    "\n",
    "min_snp = 100000 # Min SNP coverage for Y Call\n",
    "age = [0,12000]\n",
    "lat = [20,90]\n",
    "lon = [-28, 180]\n",
    "flag = [\"_contam\", \"_dup\"]\n",
    "\n",
    "df_meta[\"study\"]=df_meta[\"study\"].fillna(\"missing\") # Add Nan\n",
    "idx = df_meta[\"n_cov_snp\"]>min_snp\n",
    "df=df_meta[idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(idx)}/{len(idx)} indiviuals with >{min_snp} SNPs.\")\n",
    "df[\"include\"]=df[\"include_alt\"].astype(\"int\")\n",
    "\n",
    "### Filtering based on Age\n",
    "min_age=age[0]\n",
    "idx = df[\"age\"]>min_age\n",
    "df=df[idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(idx)}/{len(idx)} inds >{min_age} BP.\")\n",
    "\n",
    "max_age = age[1]\n",
    "idx = df[\"age\"]<max_age\n",
    "df = df[idx].reset_index(drop=True)\n",
    "print(f\"Filtering to {np.sum(idx)}/{len(idx)} inds <{max_age} BP.\")\n",
    "\n",
    "### Geographic Filtering\n",
    "if (len(lat)>0) | (len(lon)>0):\n",
    "    idx_lat = (lat[0] < df[\"lat\"]) & (df[\"lat\"] < lat[1])\n",
    "    idx_lon = (lon[0] < df[\"lon\"]) & (df[\"lon\"] < lon[1])\n",
    "    idx = (idx_lat & idx_lon)\n",
    "    df=df[idx].reset_index(drop=True)\n",
    "    print(f\"Kept {np.sum(idx)}/{len(idx)} inds with matching lat/lon.\")\n",
    "\n",
    "### Flag tricky Indivdiuals\n",
    "idx = df[\"clst\"].str.contains(\"|\".join(flag))\n",
    "print(f\"Kept {np.sum(~idx)}/{len(idx)} inds with good cluster labels.\")\n",
    "df=df[~idx].reset_index(drop=True)\n",
    "df = df.sort_values(by=\"avg_cov_snp\", ascending=False)\n",
    "idx = df[\"Master ID\"].duplicated()\n",
    "print(f\"Kept {np.sum(~idx)}/{len(idx)} unique Master IDs.\")\n",
    "df=df[~idx].reset_index(drop=True)\n",
    "\n",
    "### Extract Males\n",
    "idx= df[\"sex\"]==\"M\"\n",
    "print(f\"Kept {np.sum(idx)}/{len(idx)} Males.\")\n",
    "df=df[idx].reset_index(drop=True)\n",
    "\n",
    "### Flag Punic Individuals\n",
    "df1 = pd.read_csv(\"./data/cluster_assignments_punic.v54.1i.tsv\", sep=\"\\t\")\n",
    "print(f\"Extracted IIDs of {len(df1)} IIDs in Punic Project\")\n",
    "df_punic = pd.merge(df, df1, on=\"iid\")\n",
    "print(f\"Merged to {len(df_punic)} Punic Males\")\n",
    "\n",
    "### Remove Romans\n",
    "label_inc = [\"Punic_Early\", \"Punic_Late\", \"Punic_Late2\"]\n",
    "df_punic = df_punic[df_punic[\"label\"].isin(label_inc)]\n",
    "\n",
    "#df_punic = df_punic[~df_punic[\"label\"].str.contains(\"Roman\")]\n",
    "print(f\"Filtered to {len(df_punic)} Punic Samples based on label\")\n",
    "\n",
    "### Remove Punics from generated Meta\n",
    "df = df[~df[\"iid\"].isin(df1[\"iid\"])]\n",
    "print(f\"Filtered general Y to {len(df)} ancient, non Punic individuals\")\n",
    "\n",
    "### Go to published indivduals only\n",
    "df =df[~df[\"study\"].str.contains(\"Unpublished\")]\n",
    "print(f\"Filtered to {len(df)} published ancient males\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Browse] See Punic Y Haplogroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E1b    14\n",
       "R1b    10\n",
       "J2a     8\n",
       "G2a     7\n",
       "J1a     4\n",
       "J2b     3\n",
       "T1a     3\n",
       "I2a     2\n",
       "E1      1\n",
       "I       1\n",
       "R1a     1\n",
       "C1a     1\n",
       "L       1\n",
       "E1a     1\n",
       "J1      1\n",
       "Name: Y_haplo, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_punic[\"Y_haplo\"].str[:3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_punic[df_punic[\"Y_haplo\"].str[:2] == \"J2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J2a1a    7\n",
       "J2b2a    3\n",
       "J2a2a    1\n",
       "Name: Y_haplo, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[\"Y_haplo\"].str[:5].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse all published Y haplogroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/4059 Hits in data. 6.9968%\n"
     ]
    }
   ],
   "source": [
    "idx = df[\"Y_haplo\"].str.contains(\"J2\")\n",
    "print(f\"{np.sum(idx)}/{len(idx)} Hits in data. {np.mean(idx)*100:.4f}%\")\n",
    "df[idx].sort_values(by=\"age\", ascending=False)[100:150];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest Frequency of J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_y_haplos(df, y = \"J2\", m = 5, col_agg=\"clst\"):\n",
    "    \"\"\"\"Create top Y Haplogroup Hits for Y haplo y. \n",
    "    Return sort df (by max. frac)\"\"\"\n",
    "    dft = df.copy()\n",
    "    dft[\"match\"] = df[\"Y_haplo\"].str.contains(y)\n",
    "\n",
    "    dft2 = dft.groupby([col_agg]).agg({'iid':'size','match':'mean'}) \\\n",
    "              .rename(columns={'iid':'count'}) \\\n",
    "              .reset_index()\n",
    "    dft2[\"sum\"] = (dft2[\"match\"] * dft2[\"count\"]).astype(\"int\")\n",
    "    dft3 = dft2[dft2[\"count\"]>=m]\n",
    "    dft3 = dft3.sort_values(by=\"match\", ascending=False)\n",
    "    return dft3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dft3 = top_y_haplos(df, y=\"J2a\", m=4)[:50]\n",
    "dft3.to_csv(\"./output/tables/yfreqs/J2a.most.common.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dft3 = top_y_haplos(df, y=\"J2b\", m=4)[:50]\n",
    "dft3.to_csv(\"./output/tables/yfreqs/J2b.most.common.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of J2 in group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_freq_pergroup(df, clst = \"Israel_MLBA\", y=\"J2\"):\n",
    "    \"\"\"Calculate Y Haplogroup Frequency per Subgroup\"\"\"\n",
    "    \n",
    "    idx = df[\"clst\"].str.contains(clst)\n",
    "    print(f\"Found {np.sum(idx)}/{len(idx)} {clst} males\")\n",
    "\n",
    "    dft = df[idx]\n",
    "    idx = dft[\"Y_haplo\"].str.contains(y)\n",
    "    print(f\"Found {np.sum(idx)}/{len(idx)} {y} : {np.mean(idx):.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20/4059 Israel_MLBA males\n",
      "Found 4/20 J2 : 0.2000%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Israel_MLBA\", y=\"J2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2/4059 Israel_IA males\n",
      "Found 0/2 J2 : 0.0000%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Israel_IA\", y=\"J2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2/4059 Lebanon_MBA males\n",
      "Found 1/2 J2 : 0.5000%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Lebanon_MBA\", y=\"J2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8/4059 Lebanon_IA males\n",
      "Found 0/8 J2 : 0.0000%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Lebanon_IA\", y=\"J2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32/4059 Lebanon_IA|Lebanon_MBA|Israel_MLBA|Israel_IA males\n",
      "Found 3/32 J2a : 0.0938%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Lebanon_IA|Lebanon_MBA|Israel_MLBA|Israel_IA\", y=\"J2a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32/4059 Lebanon_IA|Lebanon_MBA|Israel_MLBA|Israel_IA males\n",
      "Found 2/32 J2b : 0.0625%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Lebanon_IA|Lebanon_MBA|Israel_MLBA|Israel_IA\", y=\"J2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4/4059 Greece_Aidonia_LBA males\n",
      "Found 2/4 J2a : 0.5000%\n"
     ]
    }
   ],
   "source": [
    "calc_freq_pergroup(df, clst = \"Greece_Aidonia_LBA\", y=\"J2a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J1a    16\n",
       "J2a     3\n",
       "E1b     3\n",
       "R1b     2\n",
       "J2b     2\n",
       "T1a     2\n",
       "J       1\n",
       "H       1\n",
       "I2a     1\n",
       "G2a     1\n",
       "Name: Y_haplo, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"clst\"].str.contains(\"Lebanon_IA|Lebanon_MBA|Israel_MLBA|Israel_IA\")][\"Y_haplo\"].str[:3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"clst\"].str.contains(\"Lebanon_IA|Lebanon_MBA|Israel_MLBA|Israel_IA\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
