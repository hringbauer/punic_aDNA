{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to calculate F_ST Matrix for Punic project\n",
    "This is run on v49.2 data from the HDF5.\n",
    "\n",
    "Development Area. Will be packed into functions for\n",
    "calculation and plotting notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "import h5py as h5py\n",
    "import allel ### To Calculate Scikit Allel\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta_df(f, path_meta=\"/n/groups/reich/hringbauer/Data/v49.2.anno.csv\"):\n",
    "    \"\"\"Create and return Meta Dataframe that matches hdf5 in format\"\"\"\n",
    "    samples = f[\"samples\"][:].astype(\"str\")\n",
    "    df_h5 = pd.DataFrame({\"iid\":samples})\n",
    "    df_meta = pd.read_csv(path_meta)\n",
    "    print(f\"Loaded {len(df_meta)} rows from Metafile\")\n",
    "    df = pd.merge(df_h5, df_meta, on=\"iid\", how=\"left\")\n",
    "    print(f\"Created matching Meta Dataframe for h5: {len(df)}\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"clst\"] = df[\"clst\"].fillna(\"Not Available\")\n",
    "    return df\n",
    "\n",
    "def get_cluster_idx(df, clst=\"\", col_clst=\"clst\", \n",
    "                    age_range=[], exact=False,\n",
    "                    include_col=\"include\"):\n",
    "    \"\"\"Get idcs of all samples within Cluster\n",
    "    If age_range, only samples in age range\"\"\"\n",
    "    if len(include_col)>0:\n",
    "        idcs1 = df[include_col]==True\n",
    "    else:\n",
    "        idcs1 = True\n",
    "        \n",
    "    if exact:\n",
    "        idcs = np.where((df[col_clst]==clst) & idcs1)[0] \n",
    "    else:\n",
    "        idcs = np.where((df[col_clst].str.contains(clst)) & idcs1)[0]\n",
    "    \n",
    "    ### Do additional Filtering\n",
    "    if len(age_range)>0:  \n",
    "        pass\n",
    "    return idcs\n",
    "\n",
    "###############################\n",
    "### Calculate the Allele Counts\n",
    "def get_ph(f, idcs):\n",
    "    \"\"\"Sample pseudohaploid data for hdf5 for\n",
    "    individuals with indices idcs\"\"\"\n",
    "    ads = f[\"calldata/AD\"][:,idcs,:2]\n",
    "    ads[ads<0]=0 # Set nmissing data to 0\n",
    "    cov = np.sum(ads, axis=2) # get the coverage per locus/indiviual\n",
    "    idx = cov>0  # Where there is some coverage\n",
    "    p = np.divide(ads[:,:,1], cov, where=idx)\n",
    "    p[~idx]=1\n",
    "    p = np.clip(p, a_min=0, a_max=1) # Santity check to deal with numerics\n",
    "    ac = np.random.binomial(1,p)\n",
    "    ac[~idx] = -1\n",
    "    return ac\n",
    "\n",
    "def get_gt(f, idcs):\n",
    "    \"\"\"Get diploid genoytpe counts\"\"\"\n",
    "    gt = f[\"calldata/GT\"][:,idcs,:]\n",
    "    assert(np.min(gt)>=0)\n",
    "    gt = np.sum(gt, axis=2) # Count #derived variants\n",
    "    return gt\n",
    "\n",
    "def calc_ac_from_ph(ph):\n",
    "    \"\"\"Calculate allele allele counts for individuals \n",
    "    with indices from hdf5 with allele counts only\n",
    "    ph: Array of pseudo-haploid [l,n]\"\"\"\n",
    "    c_ref=np.sum(ph==0, axis=1) # Sum the Counts over all Individuals\n",
    "    c_alt=np.sum(ph==1, axis=1) # Sum the Counts over all Individuals\n",
    "    \n",
    "    # Double 0,0 no problem, goes to NaN and is then caught by allel\n",
    "    return np.column_stack((c_ref, c_alt)) # Return the nx2 Allele Counts\n",
    "\n",
    "def calc_ac_from_gt(gt):\n",
    "    \"\"\"Calculate allele allele counts for individuals \n",
    "    with indices from hdf5 with allele counts only\n",
    "    ph: Array of pseudo-haploid [l,n]\"\"\"\n",
    "    c_ref= 2*np.sum(gt==0, axis=1) + np.sum(gt==1, axis=1)\n",
    "    c_alt= 2*np.sum(gt==2, axis=1) + np.sum(gt==1, axis=1)\n",
    "    return np.column_stack((c_ref, c_alt)) # Return the nx2 Allele Counts\n",
    "\n",
    "def get_ac_from_f(f, idcs, ph=True):\n",
    "    \"\"\"Get Allele Counts from HDF, \n",
    "    grouped for all indivdiuals in idcs\n",
    "    ph: Whether to use pseudo-haploid or diploid genotypes\"\"\"\n",
    "    if ph:\n",
    "        ph = get_ph(f, idcs)\n",
    "        ac = calc_ac_from_ph(ph=ph)\n",
    "    else:\n",
    "        print(\"Using diploid mode...\")\n",
    "        gt = get_gt(f, idcs)\n",
    "        ac = calc_ac_from_gt(gt)\n",
    "    return ac\n",
    "\n",
    "def calculate_ac_pop(clst, f, df, col=\"clst\", exact=False, \n",
    "                     ph=True, include_col=\"include\"):\n",
    "    \"\"\"Return allele counts for population.\n",
    "    exact: whether ther is an exact match\"\"\"\n",
    "    idcs = get_cluster_idx(df, clst=clst, exact=exact,\n",
    "                           col_clst=col, include_col=include_col)\n",
    "    ac = get_ac_from_f(f, idcs, ph=ph) \n",
    "    return ac\n",
    "\n",
    "def calculate_ac_pops(pops, f, df, col=\"clst\", ph=True, \n",
    "                      exact=False, out=True):\n",
    "    \"\"\"Calculate list of allele counts [l,2] for pops\n",
    "    f: hdf5\n",
    "    df: metafile matching f\n",
    "    pops: List of populations to extract ACs for\"\"\"\n",
    "    ### Check whether all pops have matches first:\n",
    "    idcss = [get_cluster_idx(df=df, clst=pop, exact=exact, col_clst=col)\n",
    "                              for pop in pops]\n",
    "    counts = np.array(map(len, idcss))\n",
    "    if np.min(counts)==0:\n",
    "        idx = np.where(counts==0)[0]\n",
    "        raise RuntimeError(f\"Pops {pop[idx]} not found!\")\n",
    "    \n",
    "    acs=[]\n",
    "    for pop in pops:\n",
    "        idcs = get_cluster_idx(df=df, clst=pop, exact=exact, col_clst=col)\n",
    "        if len(idcs)==0:\n",
    "            raise RuntimeWarning(f\"No matching iids for {pop} not found!!\")\n",
    "        if out:\n",
    "            print(f\"Calculating counts pop: {pop}, n={len(idcs)}...\")\n",
    "        ac = get_ac_from_f(f, idcs, ph=ph) \n",
    "        acs.append(ac)\n",
    "    return acs\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "### Calculate the actual f statistics\n",
    "\n",
    "def f3_ac(pt, p1, p2, snps_okay=None, blen=1000):\n",
    "    \"\"\"Calculate f3 for Allele Counts (lx2 arrays)\n",
    "    snps_okay: Which SNPs to actually use. If none use all\n",
    "    blen: Block Nr for Bootstrap\n",
    "    \"\"\"\n",
    "    #f3 = np.mean((pt-p1)*(pt-p2))\n",
    "    f3 = allel.average_patterson_f3(pt, p1, p2, blen=blen, normed=False)\n",
    "    return [f3[0], f3[1], f3[2]]  # f4, se, z\n",
    "\n",
    "def f4_ac(p1, p2, p3, p4, snps_okay=None, blen=1000):\n",
    "    \"\"\"Calculate f4 for Allele Counts (lx2 arrays)\n",
    "    snps_okay: Which SNPs to actually use (If none use all)\n",
    "    blen: Block Nr for Bootstrap\n",
    "    \"\"\"\n",
    "    f4 = allel.average_patterson_d(p1, p2, p3, p4, blen=blen)\n",
    "    return [f4[0], f4[1], f4[2]]  # f4, se, z\n",
    "\n",
    "def fst_ac(p1, p2, blen=1000):\n",
    "    \"\"\"Calculate f3 for Allele Counts (lx2 arrays)\n",
    "    blen: Block Nr for Bootstrap\n",
    "    A sim wrapper, so later on different methods can be implemented.\n",
    "    Return fst, se, z value (based on jackkniving)\n",
    "    \"\"\"\n",
    "    res = allel.average_patterson_fst(p1, p2, blen=blen)\n",
    "    f4, se = res[0], res[1]\n",
    "    z = f4 / se # Calculate the z-Value\n",
    "    return [res[0], res[1], z]  # f4, se, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25098 rows from Metafile\n",
      "Created matching Meta Dataframe for h5: 19260\n",
      "Found 1994 Duplicate\n",
      "Set 17266 Rows to Include=True\n",
      "CPU times: user 242 ms, sys: 310 ms, total: 552 ms\n",
      "Wall time: 671 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_anno = \"/n/groups/reich/hringbauer/Data/v49.2.anno.csv\"\n",
    "path_h5 = \"/n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v49.2/all_ch.h5\"\n",
    "#path_meta = \"/n/groups/reich/hringbauer/Data/\"/v49.2_punic_meta.tsv\"\n",
    "\n",
    "f = h5py.File(path_h5, \"r\")\n",
    "df = create_meta_df(f, path_meta=path_anno)\n",
    "\n",
    "### Get only the highest coverage individuals\n",
    "\n",
    "df1 = df.sort_values(by=\"n_cov_snp\", ascending=False).copy()\n",
    "idx = df1.duplicated(subset=\"Master ID\", keep='first')\n",
    "print(f\"Found {np.sum(idx)} Duplicate\")\n",
    "iids = df1[\"iid\"][~idx]\n",
    "\n",
    "idx_unique = df[\"iid\"].isin(iids)\n",
    "\n",
    "df[\"include\"]= False\n",
    "df.loc[idx_unique, \"include\"] = True\n",
    "print(f\"Set {np.sum(idx_unique)} Rows to Include=True\")\n",
    "### Merge in the cluster label\"s\n",
    "#df1 = pd.read_csv(path_meta, sep=\"\\t\")\n",
    "### Only include unique,unrelated samples\n",
    "#df1 = df1[df1[\"include\"]==1].copy().reset_index(drop=True) \n",
    "#df1 = pd.merge(df,df1[[\"iid\", \"label_region\", \"include\"]], on=\"iid\", how=\"left\")\n",
    "#df1.loc[df1[\"label_region\"].isnull(), \"label_region\"]=\"not assigned\"\n",
    "#assert(len(df1)==len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataframe\n",
    "Set custom Labels - for Punic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 145 Individuals\n"
     ]
    }
   ],
   "source": [
    "df_context = pd.read_csv(\"./output/tables/reference_samples_plot.v49.2.tsv\", sep=\"\\t\")\n",
    "print(f\"Loaded {len(df_context)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()   # Copy to edit\n",
    "\n",
    "\n",
    "### Set the Akzhiv Indivdiuals\n",
    "idx = df[\"loc\"].isnull()\n",
    "df[idx] =\"not assigned\"\n",
    "idx = df[\"loc\"].str.contains(\"Akhziv\")\n",
    "df1.loc[idx, \"clst\"] = \"Israel_Phoenician\"\n",
    "\n",
    "### Set the Core Punic Individuals\n",
    "### Old\n",
    "\n",
    "### Young\n",
    "\n",
    "### African Cline\n",
    "\n",
    "\n",
    "\n",
    "### Drop Indivdiuals\n",
    "iids_na = [\"I22257\"]\n",
    "for iid in iids_na:\n",
    "    idx = df[\"iid\"]==iid\n",
    "    assert(np.sum(idx)>0)\n",
    "    df1.loc[idx, \"clst\"]=\"ignore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F_ST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating counts pop: CanaryIslands_Guanche.SG, n=5...\n",
      "Calculating counts pop: Israel_Phoenician, n=15...\n",
      "Calculating counts pop: Italy_Sardinia_BA_Nuragic, n=16...\n",
      "CPU times: user 54.6 s, sys: 3.99 s, total: 58.6 s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pops = [\"CanaryIslands_Guanche.SG\", \"Israel_Phoenician\", \n",
    "        \"Italy_Sardinia_BA_Nuragic\"]\n",
    "\n",
    "acs = calculate_ac_pops(pops=pops, \n",
    "                        f=f, df=df1, col=\"clst\", \n",
    "                        exact=False, out=True, ph=True)\n",
    "\n",
    "### Calculate the outgroup f3\n",
    "#fst_ac(acs[2], acs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.018021004179348755, 0.0005648515295721015, 31.903966327223042]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculate the outgroup f3\n",
    "fst_ac(acs[1], acs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline of Calculating all F_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 11 Populations\n",
      "Calculating counts pop: Israel_MLBA, n=35...\n",
      "Calculating counts pop: Spain_IA, n=20...\n",
      "Calculating counts pop: Italy_Sicily_IA_Polizzello, n=19...\n",
      "Calculating counts pop: Italy_Sardinia_EBA, n=13...\n",
      "Calculating counts pop: Greece_BA_Mycenaean, n=15...\n",
      "Calculating counts pop: Italy_Sardinia_BA_Nuragic, n=11...\n",
      "Calculating counts pop: CanaryIslands_Guanche.SG, n=5...\n",
      "Calculating counts pop: Tunisia_N, n=4...\n",
      "Calculating counts pop: Italy_Sicily_MBA, n=7...\n",
      "Calculating counts pop: Spain_Menorca_LBA, n=3...\n",
      "Calculating counts pop: Tunisia_LN, n=2...\n",
      "Finished pre-processing all freqs. Starting Allele Count calculation!\n",
      "CPU times: user 3min 54s, sys: 9.75 s, total: 4min 4s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pops = [\"Israel_MLBA\", \"Spain_IA\", \"Italy_Sicily_IA_Polizzello\",\n",
    "        \"Italy_Sardinia_EBA\", \"Greece_BA_Mycenaean\", \"Italy_Sardinia_BA_Nuragic\",\n",
    "        \"CanaryIslands_Guanche.SG\", \"Tunisia_N\", \"Italy_Sicily_MBA\", \"Spain_Menorca_LBA\",\n",
    "        \"Tunisia_LN\"]\n",
    "col = \"clst\"\n",
    "ph = True\n",
    "\n",
    "print(f\"Calculating {len(pops)} Populations\")\n",
    "acs = calculate_ac_pops(pops=pops, f=f, df=df, col=col, \n",
    "                        exact=True, out=True, ph=ph)    \n",
    "print(\"Finished pre-processing all freqs. Starting Allele Count calculation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/reich/hringbauer/explore_ntbk/jptvenv37/lib/python3.7/site-packages/allel/stats/admixture.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = (ac[:, 0] * ac[:, 1]) / (an * (an - 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished calculation!\n",
      "CPU times: user 15.9 s, sys: 95.5 ms, total: 16 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Calculate all Fst\n",
    "res, res_h = [], []  # Vector for the Results\n",
    "pops1, pops2 = [], [] # Vector for the populations pairs\n",
    "\n",
    "k = len(pops)\n",
    "for i1, i2 in it.combinations(np.arange(k),2):\n",
    "    # Save for the population list\n",
    "    pops1.append(pops[i1])\n",
    "    pops2.append(pops[i2])    \n",
    "    ### Do the fst Calculation\n",
    "    res_new = fst_ac(acs[i1], acs[i2])\n",
    "    res.append(res_new)\n",
    "    \n",
    "print(\"\\nFinished calculation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns=[]\n",
    "for pop in pops:\n",
    "    idcs = get_cluster_idx(df=df, clst=pop, \n",
    "                           exact=False, col_clst=col)\n",
    "    ns.append(len(idcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 55 pw. Comparisons.\n",
      "Saved 11 populations.\n"
     ]
    }
   ],
   "source": [
    "#res= np.array(res)\n",
    "\n",
    "df_fst = pd.DataFrame({\"s1\": pops1, \"s2\": pops2,\n",
    "               \"fst\": res[:,0], \"se\": res[:,1], \"z\": res[:,2]})\n",
    "\n",
    "### Save the F_ST-Matrix as well as the populaition:\n",
    "folder = \"./output/tables/fst/v49.2/\"  # Where to save: fst-mat-hudson\n",
    "\n",
    "df_fst.to_csv(folder + 'fst.csv', index=False) # Save the Values\n",
    "print(f\"Saved {len(df_fst)} pw. Comparisons.\")\n",
    "\n",
    "### Do the pop size numbers\n",
    "df_pops = pd.DataFrame({\"pop\": pops, \"n\": ns})\n",
    "df_pops.to_csv(folder + 'pops.csv', index=False) # Save the Values\n",
    "print(f\"Saved {len(df_pops)} populations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
