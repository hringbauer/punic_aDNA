{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Files for qpAdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "# For Arial Font\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'   # Set the defaul\n",
    "# Make sure to have the font installed (it is on cluster for Harald)\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/n/groups/reich/DAVID/V49/V49.2/v49.2\"\n",
    "ind_path = base_path + \".ind\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Population File (what to pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pops(df, string, col=\"clst\", output=1):\n",
    "    \"\"\"Return list of clusters that contain string.\"\"\"\n",
    "    df1 = df[df[col].str.contains(string)]\n",
    "    \n",
    "    if output==1:\n",
    "        print(f\"{string}: {len(df1)} \")\n",
    "    elif output==2:\n",
    "        print(df1[col].value_counts())\n",
    "        \n",
    "    clsts = list(set(df1[col].values))\n",
    "    return clsts\n",
    "\n",
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./explore_ntbk/parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25098 Individuals\n"
     ]
    }
   ],
   "source": [
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1281 \n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "### Testing for single Populations Populations\n",
    "return_pops(df_ind, string=\"Spain\", \n",
    "            output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Ones v46.3\n",
    "pops = [\"Algeria\", \"Morocco\", \"Tunisia\", \"Punic\", \"Phoenician\", \"Spain_Vandal\", \"Spain_LBA\",\n",
    "        \"Sardinia\", \"Ibiza\", \"Israel_MLBA\", \"Israel_LBA\", \"Ashkelon\", \"Sicily\", \"Hellenistic\",\n",
    "        \"Israel_IA\", \"Israel_EIA\", \"Israel_Persian\", \"Gibraltar\", \"Lebanon\",\n",
    "        \"Spain_EBA_Afric\", \"Spain_BellBeaker_oAfrica\", \"Spain_Greek\",\n",
    "        \"Spain_Hellenistic\", \"Spain_IA\", \"Italy_Sardinia_C_oAfrica\", \n",
    "        \"Nigeria_IA\", \"Nigeria_Medieval\", \"Mallorca\", \"Menorca\", \n",
    "        \"Egypt_Hellenistic\", \"Egypt_Roman\", \"Egypt_Dynastic\", \n",
    "        \"Formentera\", \"Aritgues\",  \"Greece_\", \"Guanche\", \"Israel_C\", \n",
    "        \"Spain_EN\", \"France_EN\"]\n",
    "\n",
    "exclude_strings = [\"_lc\", \"contam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algeria: 4 \n",
      "Morocco: 18 \n",
      "Tunisia: 38 \n",
      "Punic: 162 \n",
      "Phoenician: 17 \n",
      "Spain_Vandal: 8 \n",
      "Spain_LBA: 27 \n",
      "Sardinia: 224 \n",
      "Ibiza: 1 \n",
      "Israel_MLBA: 59 \n",
      "Israel_LBA: 4 \n",
      "Ashkelon: 10 \n",
      "Sicily: 243 \n",
      "Hellenistic: 92 \n",
      "Israel_IA: 5 \n",
      "Israel_EIA: 1 \n",
      "Israel_Persian: 1 \n",
      "Gibraltar: 4 \n",
      "Lebanon: 38 \n",
      "Spain_EBA_Afric: 3 \n",
      "Spain_BellBeaker_oAfrica: 2 \n",
      "Spain_Greek: 10 \n",
      "Spain_Hellenistic: 6 \n",
      "Spain_IA: 52 \n",
      "Italy_Sardinia_C_oAfrica: 2 \n",
      "Nigeria_IA: 4 \n",
      "Nigeria_Medieval: 3 \n",
      "Mallorca: 1 \n",
      "Menorca: 8 \n",
      "Egypt_Hellenistic: 6 \n",
      "Egypt_Roman: 4 \n",
      "Egypt_Dynastic: 5 \n",
      "Formentera: 2 \n",
      "Aritgues: 8 \n",
      "Greece_: 127 \n",
      "Guanche: 5 \n",
      "Israel_C: 32 \n",
      "Spain_EN: 21 \n",
      "France_EN: 9 \n",
      "Loaded 405 Populations\n",
      "After Exclusion 333\n"
     ]
    }
   ],
   "source": [
    "clsts = [return_pops(df_ind, string=pop, output=1) for pop in pops]\n",
    "\n",
    "clsts = [inner for ls in clsts for inner in ls]\n",
    "clsts = list(set(clsts)) # Filter to unique Elements\n",
    "print(f\"Loaded {len(clsts)} Populations\")\n",
    "\n",
    "### Exclude Strings\n",
    "for ex in exclude_strings:\n",
    "    clsts = [c for c in clsts if ex not in c]\n",
    "print(f\"After Exclusion {len(clsts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exclude Kerkouane in external sharing\n",
    "#clsts = [c for c in clsts if \"Tunisia_Punic\" not in c]\n",
    "#len(clsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save List of populations to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 333 clusters to keep to: ./parfiles/keep_pops.v49.2\n"
     ]
    }
   ],
   "source": [
    "version = \"49.2\"\n",
    "v0 = version.split(\".\")[0]\n",
    "#keep = np.array([\"Anatolia_N\", \"Iberia_HG\"])\n",
    "keep = np.array(clsts)\n",
    "path_keep = f\"./parfiles/keep_pops.v{version}\"\n",
    "np.savetxt(path_keep, keep, fmt=\"%s\")\n",
    "print(f\"Saved {len(clsts)} clusters to keep to: {path_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag out individuals who should not be extracted\n",
    "Idea: Some individuals should not be included in the final .ind file. To do this,\n",
    "I create a .ind file where the population of these is set to \"Ignore1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged out 752/25098 downsampled Individuals\n",
      "Saved to: /n/groups/reich/hringbauer/Data/v49.2.all.flagged.ind\n"
     ]
    }
   ],
   "source": [
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{version}/v{version}\"\n",
    "save_path = f\"/n/groups/reich/hringbauer/Data/v{version}.all.flagged.ind\"\n",
    "\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "idx = df_ind[\"iid\"].str.endswith(\"_d\")\n",
    "df_ind.loc[idx, \"clst\"] = \"Ignore1\"\n",
    "print(f\"Flagged out {np.sum(idx)}/{len(idx)} downsampled Individuals\")\n",
    "df_ind.to_csv(save_path, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run convertf (with population list to keep)\n",
    "Additional parameters (such as position of output file) are coded into the parameter file\n",
    "\n",
    "Takes about 20 minutes for all individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/qpAdm/convertf.anc_only.49.2.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V49/V49.2/v49.2\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2\n",
      "genotypename: /n/groups/reich//DAVID/V49/V49.2/v49.2.geno\n",
      "snpname: /n/groups/reich//DAVID/V49/V49.2/v49.2.snp\n",
      "indivname: /n/groups/reich/hringbauer/Data/v49.2.all.flagged.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/keep_pops.v49.2\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 5750\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5368709120 bytes\n",
      "read 6442450944 bytes\n",
      "read 7516192768 bytes\n",
      "read 7737156575 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 1233013 indivs: 25098\n",
      "after compress: snps: 1233013 indivs: 984\n",
      "numvalidind:    984  maxmiss: 984001\n",
      "packedancestrymap output\n",
      "numsnps output: 1233013\n",
      "##end of convertf:      865.790 seconds cpu      759.456 Mbytes in use\n",
      "CPU times: user 20.1 s, sys: 4.48 s, total: 24.6 s\n",
      "Wall time: 14min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = f\"./parfiles/qpAdm/convertf.anc_only.{version}.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge in Lazaridis Ancients with mergeit (with population list to keep)\n",
    "Takes about 3 min for v49.2\n",
    "Again: Some definitions are in the parfile. Please check/modify there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/qpAdm/parMerge.v49.2\n",
      "BASE: /n/groups/reich/hringbauer/git/punic_aDNA\n",
      "S1: eigenstrat/anc_only.v49.2\n",
      "S2: eigenstrat/additional/MinMyc\n",
      "OUT: eigenstrat/combined/punic.v49.2\n",
      "geno1: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.geno\n",
      "snp1: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.snp\n",
      "ind1: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.ind\n",
      "geno2: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.geno\n",
      "snp2: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.snp\n",
      "ind2: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.ind\n",
      "genooutfilename: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v49.2.geno\n",
      "snpoutfilename: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v49.2.snp\n",
      "indoutfilename: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v49.2.ind\n",
      "docheck: YES\n",
      "hashcheck: NO\n",
      "allowdups: YES\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "numsnps input: 1233013 1233013\n",
      "packedancestrymap output\n",
      "numsnps output: 1196712  numindivs: 1313\n",
      "\n",
      "\n",
      "Histogram of checkmatch return codes\n",
      "kode:   -2  36301  A/T or C/G and strandcheck\n",
      "kode:    1 1196712  SNP OK (no flip)\n",
      "total:        1233013\n",
      "\n",
      "##end of mergeit:      179.550 seconds cpu     1356.235 Mbytes in use\n",
      "CPU times: user 4.27 s, sys: 895 ms, total: 5.17 s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bin_merge_it = \"/n/groups/reich/hringbauer/o2bin/mergeit\"\n",
    "parfile_path = \"./parfiles/qpAdm/parMerge.v49.2\"\n",
    "\n",
    "! $bin_merge_it -p $parfile_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Individual File [Stand Alone from here]\n",
    "Overwrite Individuals with their individual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_ind_df(df, string, col=\"clst\", \n",
    "                     output=False, overwrite=\"\", iids=False):\n",
    "    \"\"\"Overwrite Individual Dataframe where col\n",
    "    contains string. Return modified dataframe (Copy)\n",
    "    where overwrite is the new Cluster ID\n",
    "    iids: Overwrite with IIDs if True!\"\"\"\n",
    "    idx = df[col].str.contains(string)\n",
    "    \n",
    "    if np.sum(idx)==0:\n",
    "        if output: \n",
    "            print(\"No Indivdiuals found\")\n",
    "        return\n",
    "    \n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Matches\")\n",
    "        print(df[idx][col].value_counts())\n",
    "    \n",
    "    ### Actually  overwrite the Column\n",
    "    if len(overwrite)>0:\n",
    "        df.loc[idx, col] = overwrite\n",
    "        if output: \n",
    "            print(f\"{np.sum(idx)} Overwritten!\")\n",
    "            \n",
    "    if iids:\n",
    "        df.loc[idx, col] = df.loc[idx, \"iid\"] \n",
    "        \n",
    "        \n",
    "### Overwrite Individual IIDs\n",
    "def modifiy_iid_files(df_ind, pops_overwrite, \n",
    "                      pops_overwrite12=[], ind_modified=\"\"):\n",
    "    \"\"\"Modify .ind file. Overwrite individuals from pops_overwrite (list)\n",
    "    with their individuals labels. \n",
    "    df_int: Dataframe from Individuals.\n",
    "    pops_overwrite12: [[pop1,pop2]] list (nx2). Overwrites ALL string matches\n",
    "    for pop1 (contain) with pop2\"\"\"\n",
    "    \n",
    "    ### Overwrite with other Label\n",
    "    for pop1,pop2 in pops_overwrite12:\n",
    "        overwrite_ind_df(df_ind, pop1, overwrite=pop2)\n",
    "        \n",
    "    ### Overwrite with individual IIds\n",
    "    for pop in pops_overwrite:\n",
    "        overwrite_ind_df(df_ind, pop, \n",
    "                     iids=True, output=True)\n",
    "    \n",
    "    ### Save here\n",
    "    df_ind.to_csv(ind_modified, sep=\" \", index=None, header=False)\n",
    "    print(f\"Saved {len(df_ind)} Individuals to {ind_modified}\")\n",
    "    \n",
    "def set_clst_to_iid(df_ind, iids_overwrite, \n",
    "                    pops_overwrite12=[], savepath=\"\"):\n",
    "    \"\"\"Modify .ind file. Overwrite individuals from pops_overwrite (list)\n",
    "    with their individuals labels. \n",
    "    df_int: Dataframe from Individuals.\n",
    "    pops_overwrite12: [[pop1,pop2]] list (nx2). Overwrites ALL string matches\n",
    "    for pop1 (contain) with pop2\"\"\"\n",
    "    \n",
    "    ### Overwrite with other Label\n",
    "    idx = df_ind[\"iid\"].isin(iids)\n",
    "    print(f\"Overwriting {np.sum(idx)} Individuals\")\n",
    "    df_ind.loc[idx, \"clst\"] = df_ind.loc[idx, \"iid\"]\n",
    "        \n",
    "    ### Overwrite with other Label\n",
    "    for pop1,pop2 in pops_overwrite12:\n",
    "        overwrite_ind_df(df_ind, pop1, overwrite=pop2)\n",
    "    \n",
    "    ### Save here\n",
    "    if len(savepath)>0:\n",
    "        df_ind.to_csv(savepath, sep=\" \", index=None, header=False)\n",
    "        print(f\"Saved {len(df_ind)} Individuals to {savepath}\")\n",
    "        \n",
    "def set_iids_to_clst(df_ind, iids=[], clst=\"\", savepath=\"\"):\n",
    "    \"\"\"Set List of Indivdiuals to Cluster Label.\n",
    "    savepath: If defined: Save to there.\"\"\"\n",
    " \n",
    "    idx = df_ind[\"iid\"].isin(iids)\n",
    "    print(f\"Overwriting {np.sum(idx)} Individuals to {clst}\")\n",
    "    df_ind.loc[idx, \"clst\"] = clst\n",
    "    \n",
    "    ### Save here\n",
    "    if len(savepath)>0:\n",
    "        df_ind.to_csv(savepath, sep=\" \", index=None, header=False)\n",
    "        print(f\"Saved {len(df_ind)} Individuals to {savepath}\")  \n",
    "    return df_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: Overwrite narrow target Individuals\n",
    "(For testing please see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1255 Individuals\n"
     ]
    }
   ],
   "source": [
    "ind_merged = f\"./eigenstrat/combined/punic.v{vrs}.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play around with Individual df to identify clusters of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Israel\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Only overwrite the Punics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 Matches\n",
      "Italy_Sicily_Punic                               35\n",
      "Tunisia_Punic                                    27\n",
      "Spain_Punic                                      14\n",
      "Italy_Sardinia_Punic                             10\n",
      "Italy_Sardinia_IA_Punic_1                         5\n",
      "Italy_Sardinia_Punic_oNAfrica                     4\n",
      "Italy_Sardinia_IA_Punic_2                         4\n",
      "Italy_Sicily_Punic_oNearEast                      3\n",
      "Spain_Punic_oAfrican2                             2\n",
      "Italy_Sicily_Punic_Roman                          2\n",
      "Spain_Punic_oEurope                               2\n",
      "Italy_Sicily_Punic_oEuropean                      2\n",
      "Spain_Punic_o.3rd.degree.relative.cluster         2\n",
      "Italy_Sicily_Punic_oLevant                        2\n",
      "Italy_Sardinia_Punic_oCaucasus                    1\n",
      "Spain_Punic_Roman_oAfrican3                       1\n",
      "Spain_Punic_Roman_oEuropean2                      1\n",
      "Spain_Punic_o.3rd.degree.relative.cluster_alt     1\n",
      "Spain_Punic_Roman_o3                              1\n",
      "Spain_Punic_possible                              1\n",
      "Italy_Sardinia_Punic_oLevant                      1\n",
      "Italy_Sardinia_Punic_Roman                        1\n",
      "Spain_Punic_o4                                    1\n",
      "Tunisia_Punic_oAfrica                             1\n",
      "Spain_Punic_Roman                                 1\n",
      "Spain_Punic_Roman_oAfrican1                       1\n",
      "Ibiza_Punic.SG                                    1\n",
      "Italy_Sardinia_Punic_oEurope                      1\n",
      "Tunisia_Punic_1d.rel.I24199                       1\n",
      "Tunisia_Punic_mother.or.daughter.I24040           1\n",
      "Italy_Sicily_Punic_Roman_oEurope                  1\n",
      "Name: clst, dtype: int64\n",
      "No Indivdiuals found\n",
      "Found 19 Matches\n",
      "Israel_Phoenician               13\n",
      "Spain_Phoenician_Hypogeum        5\n",
      "Israel_Phoenician_oUpperNile     1\n",
      "Name: clst, dtype: int64\n",
      "Saved 1255 Individuals to ./eigenstrat/combined/punic.v49.0_ind.ind\n"
     ]
    }
   ],
   "source": [
    "### Populations to overwrite. Typically because they have the \".SG\" label\n",
    "pops_overwrite12 = [[\"Morocco_LN\", \"Morocco_LN\"], [\"Morocco_EN\", \"Morocco_EN\"],\n",
    "                   [\"Morocco_Iberomaurusian\",\"Morocco_Iberomaurusian\"], [\"YRI\", \"YRI\"]]\n",
    "\n",
    "### Population to overwrite because they are the target\n",
    "pops_overwrite = [\"Punic\", \"Sicily_Punic\", \"Phoen\"] # \"Sardinia\", \"Spain\" \"Algeria\", \n",
    "\n",
    "ind_modified=\"./eigenstrat/combined/punic.v49.0_ind.ind\"    # Where to save the modified version to\n",
    "\n",
    "modifiy_iid_files(df_ind, pops_overwrite=pops_overwrite, \n",
    "                  pops_overwrite12=pops_overwrite12,\n",
    "                  ind_modified = ind_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Split up Iberian Bronze Age and Sardinian Nuragic too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_overwrite = [\"Algeria_N\", \"Punic\", \"Italy_Sicily_Phoenician\",\n",
    "                  \"Sicily_IA_Polizzello\", \"Sicani\", \"Phoen\",\n",
    "                  \"Morocco_LN\", \"Punic_oAfrican\", \n",
    "                  \"Iberia_North_BA_Africa_all\", \"Iberia_BA\", \"Iberia_IA\",\n",
    "                  \"Iberia_Greek\", \"Iberia_Hellenistic\",\n",
    "                  \"Iberia_BellBeaker_o\", \"Gibraltar_N\", \n",
    "                  \"Iberia_Iberian\", \"Iberia_Celtiberian\", \"Iberia_Tartessian\",\n",
    "                  \"Italy_Sardinia_C_o\", \"Nuragic\",\n",
    "                  \"Nigeria_IA\", \"Nigeria_Medieval\"\n",
    "                  ]\n",
    "\n",
    "pops_overwrite12 = [[\"Morocco_LN\", \"Morocco_LN\"], [\"Morocco_EN\", \"Morocco_EN\"],\n",
    "                   [\"Morocco_Iberomaurusian\",\"Morocco_Iberomaurusian\"], [\"YRI\",\"YRI\"]]\n",
    "\n",
    "ind_modified=\"./eigenstrat/combined/punic.v49.0_ind1.ind\"    # Where to save the modified version to\n",
    "\n",
    "modifiy_iid_files(df_ind, pops_overwrite=pops_overwrite, \n",
    "                  pops_overwrite12=pops_overwrite12,\n",
    "                  ind_modified = ind_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Modify all targets for distal modelling (Punics and Proximal Sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1255 Individuals\n",
      "Saving meta of 159 Individuals for further processing.\n"
     ]
    }
   ],
   "source": [
    "ind_merged=\"./eigenstrat/combined/punic.v49.0.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")\n",
    "\n",
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v49.0.anno.csv\")\n",
    "dft = pd.merge(df_ind[\"iid\"], df_meta[[\"iid\", \"loc\", \"clst\", \"n_cov_snp\", \"age\", \"lat\", \"lon\"]], on=\"iid\")\n",
    "\n",
    "df_labels = pd.read_csv(\"./data/qpAdm_pops.tsv\", sep=\"\\t\")\n",
    "\n",
    "dfs = []\n",
    "for index, row in df_labels.iterrows():\n",
    "    dft1 = dft[dft[\"clst\"].str.contains(row[\"clst\"]) & (dft[\"loc\"] == row[\"loc\"])]\n",
    "    dfs.append(dft1)\n",
    "    \n",
    "df_targets = pd.concat(dfs)\n",
    "\n",
    "print(f\"Saving meta of {len(df_targets)} Individuals for further processing.\")\n",
    "#df_targets.to_csv(\"./output/tables/qpadm.targets.distal.v46.3.tsv\", sep=\"\\t\", index=False)\n",
    "iids = df_targets[\"iid\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 0 Indivdiuals for a rerun.\n"
     ]
    }
   ],
   "source": [
    "### Only save if additional Individuals need a rerun\n",
    "df_temp = pd.read_csv(\"./output/tables/qpadm.targets.distal.v46.3.tsv\", sep=\"\\t\")\n",
    "idx = [iid not in df_temp[\"iid\"].values for iid in iids]\n",
    "#df_targets[idx].to_csv(\"./output/tables/qpadm.targets.distal.v46.3.add.tsv\", sep=\"\\t\")\n",
    "print(f\"Saved {np.sum(idx)} Indivdiuals for a rerun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_clst_to_iid(df_ind, iids, pops_overwrite12=[], \n",
    "                savepath=\"./eigenstrat/combined/punic.v46.3_ind2.ind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Modify Individual PCA clusters of Punic Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1255 Individuals\n",
      "Overwriting 9 Individuals to PunicCline\n",
      "Overwriting 3 Individuals to PunicAfrican\n",
      "Saved 1255 Individuals to ./eigenstrat/combined/punic.v49.0_punic_clst.ind\n"
     ]
    }
   ],
   "source": [
    "ind_merged=\"./eigenstrat/combined/punic.v49.0.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")\n",
    "\n",
    "### Modify the Clusters\n",
    "iids_afr_punic =  [\"I18193\", \"I18189\", \"I22093\"]  # \"I22113\" high but not high enough\n",
    "iids_afr_cline = [\"I21966\", \"I21984\", \"I22094\", \"I22090\", \"VIL011\", \"VIL006\", \"VIL009\", \"VIL010\", \"VIL007\"] # but not VIL004\n",
    "\n",
    "df_ind = set_iids_to_clst(df_ind, iids=iids_afr_cline, clst=\"PunicCline\", savepath=\"\")\n",
    "df_ind = set_iids_to_clst(df_ind, iids=iids_afr_punic, clst=\"PunicAfrican\", savepath=\"\")\n",
    "\n",
    "savepath=\"./eigenstrat/combined/punic.v49.0_punic_clst.ind\"\n",
    "#df_ind.to_csv(savepath, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} Individuals to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>sex</th>\n",
       "      <th>clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>I11788</td>\n",
       "      <td>M</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>I11794</td>\n",
       "      <td>M</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>I11806</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>I22271</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>I22256</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>I22257</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician_o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>I22258</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>I22251</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>I22253</td>\n",
       "      <td>M</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>I22254</td>\n",
       "      <td>M</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>I22252</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>I22260</td>\n",
       "      <td>M</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>I11804</td>\n",
       "      <td>F</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>I11805</td>\n",
       "      <td>M</td>\n",
       "      <td>Israel_Phoenician</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        iid sex                 clst\n",
       "304  I11788   M    Israel_Phoenician\n",
       "350  I11794   M    Israel_Phoenician\n",
       "443  I11806   F    Israel_Phoenician\n",
       "703  I22271   F    Israel_Phoenician\n",
       "762  I22256   F    Israel_Phoenician\n",
       "764  I22257   F  Israel_Phoenician_o\n",
       "765  I22258   F    Israel_Phoenician\n",
       "766  I22251   F    Israel_Phoenician\n",
       "771  I22253   M    Israel_Phoenician\n",
       "774  I22254   M    Israel_Phoenician\n",
       "777  I22252   F    Israel_Phoenician\n",
       "779  I22260   M    Israel_Phoenician\n",
       "869  I11804   F    Israel_Phoenician\n",
       "875  I11805   M    Israel_Phoenician"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Phoen\")]\n",
    "\n",
    "#pops = [\"Spain_IA_Tartessian\", \"Spain_IA_Celt\", \"Italy_Sardinia_BA_Nuragic\", \n",
    "#        \"Italy_Sicily_IA_Sicani\", \"Greece_BA_Mycenaean\", \"Israel_Phoenician\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to David's Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(\"/n/groups/reich/hringbauer/Data/Unpublished_data.tsv\", sep=\"\\t\")\n",
    "age_col = \"Average of 95.4% date range in calBP (defined as 1950 CE)  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.str.contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_col = 'Group_ID (format convention which we try to adhere to is \"Country_<Geographic.Region_<Geographic.Subregion_>><Archaeological.Period.Or.DateBP_<Alternative.Archaeological.Period_>><Archaeological.Culture_<Alternative.Archaeological.Culture>><genetic.subgrouping.index.if.necessary_><\"o_\"sometimes.with.additional.detail.if.an.outlier><additional.suffix.especially.relative.status.if.we.recommend.removing.from.main.analysis.grouping><\"contam_\".if.contaminated><\"lc_\".if.<15000.SNPs.on.autosomal.targets><\".SG\".or.\".DG\".if.shotgun.data>; HG=hunter-gatherer, N=Neolithic, C=Chalcolithic/CopperAge, BA=BronzeAge, IA=IronAge, E=Early, M=Middle, L=Late, A=Antiquity)'\n",
    "groups = df_t[group_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174 Individuals\n"
     ]
    }
   ],
   "source": [
    "clsts_list = \"|\".join(clsts)\n",
    "idx = groups.str.contains(clsts_list)\n",
    "print(f\"Found {np.sum(idx)} Individuals\")\n",
    "df_found = df_t[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found[150:174][[\"Master ID\", group_col, \"Publication\", \"Locality\", age_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found.to_csv(\"./output/tables/samples_claim.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Entries in Eigenstrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1240 Individuals\n"
     ]
    }
   ],
   "source": [
    "#ind_merged=\"./eigenstrat/anc_only.v46.3.ind\"          # What .ind to load\n",
    "ind_merged=\"./eigenstrat/combined/punic.v46.3_ind.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Italy_Sicily_IA_Polizzello    19\n",
       "Italy_Sicily_IA_Sicani         4\n",
       "Name: clst, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Sicily_IA\")][\"clst\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Outgroup: \n",
    "### Israel_MLBA Italy_Sardinia_EBA Spain_LBA Italy_Sicily_EBA Steppe_MLBA Greece_Minoan_Lassithi\n",
    "### Additional Source: Spain_IA I12433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[\"clst\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>sex</th>\n",
       "      <th>clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>I12433</td>\n",
       "      <td>F</td>\n",
       "      <td>Algeria_IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>I11896</td>\n",
       "      <td>F</td>\n",
       "      <td>Algeria_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>I13901_d</td>\n",
       "      <td>M</td>\n",
       "      <td>Algeria_Paleolithic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>I11896_d</td>\n",
       "      <td>F</td>\n",
       "      <td>Algeria_N_d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          iid sex                 clst\n",
       "314    I12433   F           Algeria_IA\n",
       "349    I11896   F            Algeria_N\n",
       "668  I13901_d   M  Algeria_Paleolithic\n",
       "903  I11896_d   F          Algeria_N_d"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Algeria\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
