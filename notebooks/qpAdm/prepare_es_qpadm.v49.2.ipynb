{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Files for qpAdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 28\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from time import time\n",
    "\n",
    "# For Arial Font\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'   # Set the defaul\n",
    "# Make sure to have the font installed (it is on cluster for Harald)\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pops(df, string, col=\"clst\", output=1):\n",
    "    \"\"\"Return list of clusters that contain string.\"\"\"\n",
    "    df1 = df[df[col].str.contains(string)]\n",
    "    \n",
    "    if output==1:\n",
    "        print(f\"{string}: {len(df1)} \")\n",
    "    elif output==2:\n",
    "        print(df1[col].value_counts())\n",
    "        \n",
    "    clsts = list(set(df1[col].values))\n",
    "    return clsts\n",
    "\n",
    "def run_convertf(path_convertf = \"./o2bin/convertf\", parfile = \"./explore_ntbk/parfiles/convertf.keep.par\"):\n",
    "    \"\"\"Runs the Downsampling\"\"\"\n",
    "    ! $path_convertf -p $parfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/n/groups/reich/DAVID/V49/V49.2/v49.2\"\n",
    "ind_path = base_path + \".ind\"\n",
    "version = \"49.2\"\n",
    "v0 = version.split(\".\")[0]\n",
    "\n",
    "pops = [\"Algeria\", \"Morocco\", \"Tunisia\", \"Punic\", \"Phoenician\", \"Spain_Vandal\", \"Spain_LBA\",\n",
    "        \"Sardinia\", \"Ibiza\",  \"Israel_MLBA\", \"Israel_LBA\", \"Israel_IA\", \"Israel_LIA\", \"Ashkelon\", \"Sicily\", \"Hellenistic\",\n",
    "        \"Israel_IA\", \"Israel_EIA\", \"Israel_Persian\", \"Gibraltar\", \"Lebanon\",\n",
    "        \"Spain_EBA_Afric\", \"Spain_BellBeaker_oAfrica\", \"Spain_Greek\",\n",
    "        \"Spain_Hellenistic\", \"Spain_IA\", \"Italy_Sardinia_C_oAfrica\", \n",
    "        \"Nigeria_IA\", \"Nigeria_Medieval\", \"Mallorca\", \"Menorca\", \n",
    "        \"Egypt_Hellenistic\", \"Egypt_Roman\", \"Egypt_Dynastic\", \"Egypt_Third\",\n",
    "        \"Spain_Roman_oAfrica2\", \"Formentera\", \"Aritgues\",  \"Greece_\", \"Guanche\", \"Israel_C\", \n",
    "        \"Spain_EN\", \"France_EN\"]\n",
    "\n",
    "exclude_strings = [\"_lc\", \"contam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25098 Individuals\n"
     ]
    }
   ],
   "source": [
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "### Testing for single Populations Populations\n",
    "return_pops(df_ind, string=\"Spain\", \n",
    "            output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsts = [return_pops(df_ind, string=pop, output=1) for pop in pops]\n",
    "\n",
    "clsts = [inner for ls in clsts for inner in ls]\n",
    "clsts = list(set(clsts)) # Filter to unique Elements\n",
    "print(f\"Loaded {len(clsts)} Populations\")\n",
    "\n",
    "### Exclude Strings\n",
    "for ex in exclude_strings:\n",
    "    clsts = [c for c in clsts if ex not in c]\n",
    "print(f\"After Exclusion {len(clsts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exclude Kerkouane in external sharing\n",
    "#clsts = [c for c in clsts if \"Tunisia_Punic\" not in c]\n",
    "#len(clsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save List of populations to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 337 clusters to keep to: ./parfiles/keep_pops.v49.2\n"
     ]
    }
   ],
   "source": [
    "clsts = clsts + [\"include\"]\n",
    "#keep = np.array([\"Anatolia_N\", \"Iberia_HG\"])\n",
    "keep = np.array(clsts)\n",
    "path_keep = f\"./parfiles/keep_pops.v{version}\"\n",
    "np.savetxt(path_keep, keep, fmt=\"%s\")\n",
    "print(f\"Saved {len(clsts)} clusters to keep to: {path_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag out individuals who should not be extracted\n",
    "Idea: Some individuals should not be included in the final .ind file. To do this,\n",
    "I create a .ind file where the population of these is set to \"Ignore1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged out 752/25098 downsampled Individuals\n",
      "Saved to: /n/groups/reich/hringbauer/Data/v49.2.all.flagged.ind\n"
     ]
    }
   ],
   "source": [
    "base_path = f\"/n/groups/reich/DAVID/V{v0}/V{version}/v{version}\"\n",
    "save_path = f\"/n/groups/reich/hringbauer/Data/v{version}.all.flagged.ind\"\n",
    "\n",
    "ind_path = base_path + \".ind\"\n",
    "\n",
    "df_ind = pd.read_csv(ind_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "idx = df_ind[\"iid\"].str.endswith(\"_d\")\n",
    "df_ind.loc[idx, \"clst\"] = \"Ignore1\"\n",
    "print(f\"Flagged out {np.sum(idx)}/{len(idx)} downsampled Individuals\")\n",
    "df_ind.to_csv(save_path, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include Indivdiuals from Ilan's list.\n",
    "Include additional individuals from Ilans list.\n",
    "To do so set their clst to include (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including 154/155 IIDs from: ./data/v49-added-samples.txt\n",
      "Saved modified .ind file to: /n/groups/reich/hringbauer/Data/v49.2.all.flagged.included.ind\n"
     ]
    }
   ],
   "source": [
    "save_path2 = f\"/n/groups/reich/hringbauer/Data/v{version}.all.flagged.included.ind\"\n",
    "path_external = \"./data/v49-added-samples.txt\"\n",
    "\n",
    "df_add = pd.read_csv(path_external, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_add.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "df_ind = pd.read_csv(save_path, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "### Add the additional Indivudals\n",
    "add_inds = [\"RISE507.508.merge.SG\", \"I13517_d\", \"I13518_d\", \"I13519_d\"] # Renamed indivdual plus some Myceneans\n",
    "search_inds = np.concatenate((df_add[\"iid\"], add_inds))\n",
    "\n",
    "idx = df_ind[\"iid\"].isin(search_inds)\n",
    "print(f\"Including {np.sum(idx)}/{len(search_inds)} IIDs from: {path_external}\")\n",
    "df_ind.loc[idx, \"clst\"] = \"include\"\n",
    "\n",
    "df_ind.to_csv(save_path2, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved modified .ind file to: {save_path2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run convertf (with population list to keep)\n",
    "Additional parameters (such as position of output file) are coded into the parameter file\n",
    "\n",
    "Takes about 10-15 minutes for all individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/qpAdm/convertf.anc_only.49.2.par\n",
      "BASE: /n/groups/reich/\n",
      "DIR: DAVID/V49/V49.2/v49.2\n",
      "OUT: hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2\n",
      "genotypename: /n/groups/reich//DAVID/V49/V49.2/v49.2.geno\n",
      "snpname: /n/groups/reich//DAVID/V49/V49.2/v49.2.snp\n",
      "indivname: /n/groups/reich/hringbauer/Data/v49.2.all.flagged.included.ind\n",
      "genooutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.geno\n",
      "snpoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.snp\n",
      "indoutfilename: /n/groups/reich//hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.ind\n",
      "outputformat: PACKEDANCESTRYMAP\n",
      "hashcheck: YES\n",
      "poplistname: /n/groups/reich//hringbauer/git/punic_aDNA/parfiles/keep_pops.v49.2\n",
      "## /n/groups/reich/hringbauer/o2bin/convertf version: 5750\n",
      "read 1073741824 bytes\n",
      "read 2147483648 bytes\n",
      "read 3221225472 bytes\n",
      "read 4294967296 bytes\n",
      "read 5368709120 bytes\n",
      "read 6442450944 bytes\n",
      "read 7516192768 bytes\n",
      "read 7737156575 bytes\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "before compress: snps: 1233013 indivs: 25098\n",
      "after compress: snps: 1233013 indivs: 1142\n",
      "numvalidind:   1142  maxmiss: 1142001\n",
      "packedancestrymap output\n",
      "numsnps output: 1233013\n",
      "##end of convertf:      862.410 seconds cpu      759.456 Mbytes in use\n",
      "CPU times: user 18.8 s, sys: 4.22 s, total: 23 s\n",
      "Wall time: 14min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_convertf(path_convertf = \"/n/groups/reich/hringbauer/o2bin/convertf\", \n",
    "             parfile = f\"./parfiles/qpAdm/convertf.anc_only.{version}.par\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Merge in Lazaridis Ancients with mergeit (with population list to keep)\n",
    "### Not needed anymore as of 49.2 as samples are merged in automatically\n",
    "Takes about 3 min for v49.2\n",
    "Again: Some definitions are in the parfile. Please check/modify there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: ./parfiles/qpAdm/parMerge.v49.2\n",
      "BASE: /n/groups/reich/hringbauer/git/punic_aDNA\n",
      "S1: eigenstrat/anc_only.v49.2\n",
      "S2: eigenstrat/additional/MinMyc\n",
      "OUT: eigenstrat/combined/punic.v49.2\n",
      "geno1: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.geno\n",
      "snp1: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.snp\n",
      "ind1: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/anc_only.v49.2.ind\n",
      "geno2: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.geno\n",
      "snp2: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.snp\n",
      "ind2: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.ind\n",
      "genooutfilename: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v49.2.geno\n",
      "snpoutfilename: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v49.2.snp\n",
      "indoutfilename: /n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/combined/punic.v49.2.ind\n",
      "docheck: YES\n",
      "hashcheck: NO\n",
      "allowdups: YES\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "packed geno read OK\n",
      "end of inpack\n",
      "numsnps input: 1233013 1233013\n",
      "packedancestrymap output\n",
      "numsnps output: 1196712  numindivs: 1321\n",
      "\n",
      "\n",
      "Histogram of checkmatch return codes\n",
      "kode:   -2  36301  A/T or C/G and strandcheck\n",
      "kode:    1 1196712  SNP OK (no flip)\n",
      "total:        1233013\n",
      "\n",
      "##end of mergeit:      167.470 seconds cpu     1356.235 Mbytes in use\n",
      "CPU times: user 3.65 s, sys: 781 ms, total: 4.43 s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bin_merge_it = \"/n/groups/reich/hringbauer/o2bin/mergeit\"\n",
    "parfile_path = \"./parfiles/qpAdm/parMerge.v49.2\"\n",
    "\n",
    "! $bin_merge_it -p $parfile_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set v49.2 Indivdual clusters for extra included indivdiuals\n",
    "Reset all the indivdiuals with \"include\" clst to the clst values from the original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25098 original individuals\n",
      "Loaded 1142 Individuals in Analysis .ind\n",
      "Saved original 1142 IIDs to: ./eigenstrat/anc_only.v49.2.org.ind\n",
      "Found 154 Indivduals that have been manually added\n",
      "Replace df of length 154 created\n",
      "Saved updated 1142 IIDs to: ./eigenstrat/anc_only.v49.2.ind\n"
     ]
    }
   ],
   "source": [
    "### Load Original Individuals\n",
    "path_load = f\"/n/groups/reich/DAVID/V{v0}/V{version}/v{version}.ind\"\n",
    "#ind_merged = f\"./eigenstrat/combined/punic.v{version}.ind\"          # What .ind to load\n",
    "#path_save_original = f\"./eigenstrat/combined/punic.v{version}.org.ind\"\n",
    "path_original = f\"./eigenstrat/anc_only.v{version}.ind\" \n",
    "path_save_original = f\"./eigenstrat/anc_only.v{version}.org.ind\"\n",
    "\n",
    "df_org = pd.read_csv(path_load, delim_whitespace=True, header=None)\n",
    "df_org.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_org)} original individuals\")\n",
    "\n",
    "### Load the Newly Set Indivdiuals\n",
    "df_ind = pd.read_csv(path_original, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals in Analysis .ind\")\n",
    "df_ind.to_csv(path_save_original, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved original {len(df_ind)} IIDs to: {path_save_original}\")\n",
    "\n",
    "idx = df_ind[\"clst\"] == \"include\"\n",
    "print(f\"Found {np.sum(idx)} Indivduals that have been manually added\")\n",
    "iids = df_ind.loc[idx, \"iid\"].values\n",
    "\n",
    "### Filter to Indivdiuals to replace\n",
    "df_replace = df_org[df_org[\"iid\"].isin(iids)].copy().reset_index(drop=True)\n",
    "print(f\"Replace df of length {len(df_replace)} created\")\n",
    "\n",
    "assert(len(iids)==len(df_replace)) # Sanity Check\n",
    "\n",
    "df_ind.set_index('iid', inplace=True, drop=False)\n",
    "df_replace.set_index('iid', inplace=True, drop=False)\n",
    "df_ind.update(df_replace, overwrite=True) ## Update in place\n",
    "assert(np.sum(df_ind.isnull().values)==0) # Sanity Check\n",
    "\n",
    "### Final saving. Overwrite original file\n",
    "df_ind.to_csv(path_original, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved updated {len(df_ind)} IIDs to: {path_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ind[df_ind.index.isin(iids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Individual File [Stand Alone from here]\n",
    "Overwrite Individuals with their individual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_ind_df(df, string, col=\"clst\", \n",
    "                     output=False, overwrite=\"\", iids=False):\n",
    "    \"\"\"Overwrite Individual Dataframe where col\n",
    "    contains string. Return modified dataframe (Copy)\n",
    "    where overwrite is the new Cluster ID\n",
    "    iids: Overwrite with IIDs if True!\"\"\"\n",
    "    idx = df[col].str.contains(string)\n",
    "    \n",
    "    if np.sum(idx)==0:\n",
    "        if output: \n",
    "            print(\"No Indivdiuals found\")\n",
    "        return\n",
    "    \n",
    "    if output:\n",
    "        print(f\"Found {np.sum(idx)} Matches\")\n",
    "        print(df[idx][col].value_counts())\n",
    "    \n",
    "    ### Actually  overwrite the Column\n",
    "    if len(overwrite)>0:\n",
    "        df.loc[idx, col] = overwrite\n",
    "        if output: \n",
    "            print(f\"{np.sum(idx)} Overwritten!\")\n",
    "            \n",
    "    if iids:\n",
    "        df.loc[idx, col] = df.loc[idx, \"iid\"] \n",
    "        \n",
    "        \n",
    "### Overwrite Individual IIDs\n",
    "def modifiy_iid_files(df_ind, pops_overwrite, \n",
    "                      pops_overwrite12=[], ind_modified=\"\"):\n",
    "    \"\"\"Modify .ind file. Overwrite individuals from pops_overwrite (list)\n",
    "    with their individuals labels. \n",
    "    df_int: Dataframe from Individuals.\n",
    "    pops_overwrite12: [[pop1,pop2]] list (nx2). Overwrites ALL string matches\n",
    "    for pop1 (contain) with pop2\"\"\"\n",
    "    \n",
    "    ### Overwrite with other Label\n",
    "    for pop1,pop2 in pops_overwrite12:\n",
    "        overwrite_ind_df(df_ind, pop1, overwrite=pop2)\n",
    "        \n",
    "    ### Overwrite with individual IIds\n",
    "    for pop in pops_overwrite:\n",
    "        overwrite_ind_df(df_ind, pop, \n",
    "                     iids=True, output=True)\n",
    "    \n",
    "    ### Save here\n",
    "    df_ind.to_csv(ind_modified, sep=\" \", index=None, header=False)\n",
    "    print(f\"Saved {len(df_ind)} Individuals to {ind_modified}\")\n",
    "    \n",
    "def set_clst_to_iid(df_ind, iids_overwrite, \n",
    "                    pops_overwrite12=[], savepath=\"\"):\n",
    "    \"\"\"Modify .ind file. Overwrite individuals from pops_overwrite (list)\n",
    "    with their individuals labels. \n",
    "    df_int: Dataframe from Individuals.\n",
    "    pops_overwrite12: [[pop1,pop2]] list (nx2). Overwrites ALL string matches\n",
    "    for pop1 (contain) with pop2\"\"\"\n",
    "    \n",
    "    ### Overwrite with other Label\n",
    "    idx = df_ind[\"iid\"].isin(iids)\n",
    "    print(f\"Overwriting {np.sum(idx)} Individuals\")\n",
    "    df_ind.loc[idx, \"clst\"] = df_ind.loc[idx, \"iid\"]\n",
    "        \n",
    "    ### Overwrite with other Label\n",
    "    for pop1,pop2 in pops_overwrite12:\n",
    "        overwrite_ind_df(df_ind, pop1, overwrite=pop2)\n",
    "    \n",
    "    ### Save here\n",
    "    if len(savepath)>0:\n",
    "        df_ind.to_csv(savepath, sep=\" \", index=None, header=False)\n",
    "        print(f\"Saved {len(df_ind)} Individuals to {savepath}\")\n",
    "        \n",
    "def set_iids_to_clst(df_ind, iids=[], clst=\"\", savepath=\"\"):\n",
    "    \"\"\"Set List of Indivdiuals to Cluster Label.\n",
    "    savepath: If defined: Save to there.\"\"\"\n",
    " \n",
    "    idx = df_ind[\"iid\"].isin(iids)\n",
    "    print(f\"Overwriting {np.sum(idx)} Individuals to {clst}\")\n",
    "    df_ind.loc[idx, \"clst\"] = clst\n",
    "    \n",
    "    ### Save here\n",
    "    if len(savepath)>0:\n",
    "        df_ind.to_csv(savepath, sep=\" \", index=None, header=False)\n",
    "        print(f\"Saved {len(df_ind)} Individuals to {savepath}\")  \n",
    "    return df_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: Overwrite narrow target Individuals\n",
    "(For testing please see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_merged = f\"./eigenstrat/combined/punic.v{vrs}.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play around with Individual df to identify clusters of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Israel\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Set clusters from Lazaridis\n",
    "Reset the clusters from Lazaridis et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1142 original individuals\n",
      "Loaded 353 label individuals\n",
      "Mota: 1\n",
      "Overwriting 1 Individuals to Mota\n",
      "Ust_Ishim: 1\n",
      "Overwriting 1 Individuals to Ust_Ishim\n",
      "Kostenki14: 1\n",
      "Overwriting 1 Individuals to Kostenki14\n",
      "GoyetQ116-1: 1\n",
      "Overwriting 1 Individuals to GoyetQ116-1\n",
      "Vestonice16: 1\n",
      "Overwriting 1 Individuals to Vestonice16\n",
      "MA1: 1\n",
      "Overwriting 1 Individuals to MA1\n",
      "ElMiron: 1\n",
      "Overwriting 1 Individuals to ElMiron\n",
      "Villabruna: 1\n",
      "Overwriting 1 Individuals to Villabruna\n",
      "EHG: 3\n",
      "Overwriting 3 Individuals to EHG\n",
      "CHG: 2\n",
      "Overwriting 2 Individuals to CHG\n",
      "Natufian: 6\n",
      "Overwriting 6 Individuals to Natufian\n",
      "Levant_N: 13\n",
      "Overwriting 13 Individuals to Levant_N\n",
      "Anatolia_N: 26\n",
      "Overwriting 26 Individuals to Anatolia_N\n",
      "WHG: 3\n",
      "Overwriting 3 Individuals to WHG\n",
      "Steppe_EMBA: 26\n",
      "Overwriting 25 Individuals to Steppe_EMBA\n",
      "Iran_N: 9\n",
      "Overwriting 9 Individuals to Iran_N\n",
      "Morocco_EN: 0\n",
      "Overwriting 0 Individuals to Morocco_EN\n",
      "Saved updated 1142 IIDs to: ./eigenstrat/anc_only.v49.2_outgroups.ind\n"
     ]
    }
   ],
   "source": [
    "path_target = f\"./eigenstrat/anc_only.v{version}.ind\"          # What .ind to load\n",
    "path_save = f\"./eigenstrat/anc_only.v{version}_outgroups.ind\" \n",
    "path_labels =  f\"/n/groups/reich/hringbauer/git/punic_aDNA/eigenstrat/additional/MinMyc.ind\"\n",
    "\n",
    "groups = [\"Mota\", \"Ust_Ishim\", \"Kostenki14\", \n",
    "       \"GoyetQ116-1\", \"Vestonice16\", \"MA1\",\n",
    "       \"ElMiron\", \"Villabruna\", \"EHG\", \"CHG\", \"Natufian\",\n",
    "       \"Levant_N\", \"Anatolia_N\", \"WHG\", \"Steppe_EMBA\",\n",
    "       \"Iran_N\", \"Morocco_EN\"]\n",
    "\n",
    "### Load the Individuals\n",
    "df_ind = pd.read_csv(path_target, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} original individuals\")\n",
    "\n",
    "df_lbls = pd.read_csv(path_labels, delim_whitespace=True, header=None)\n",
    "df_lbls.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_lbls)} label individuals\")\n",
    "\n",
    "### Reset Clusters\n",
    "for g in groups:\n",
    "    idx = (df_lbls[\"clst\"] == g)\n",
    "    print(f\"{g}: {np.sum(idx)}\")\n",
    "    iids = df_lbls[\"iid\"][idx].values\n",
    "    \n",
    "    ### Reset All the Individuals in the Target Ind\n",
    "    df_ind = set_iids_to_clst(df_ind, iids=iids, clst=g, savepath=\"\")\n",
    "    \n",
    "df_ind.to_csv(path_save, header=False, sep=\" \", index=False)\n",
    "print(f\"Saved updated {len(df_ind)} IIDs to: {path_save}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Only overwrite the Punics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Populations to overwrite. Typically because they have the \".SG\" label\n",
    "pops_overwrite12 = [[\"Morocco_LN\", \"Morocco_LN\"], [\"Morocco_EN\", \"Morocco_EN\"],\n",
    "                   [\"Morocco_Iberomaurusian\",\"Morocco_Iberomaurusian\"], [\"YRI\", \"YRI\"]]\n",
    "\n",
    "### Population to overwrite because they are the target\n",
    "pops_overwrite = [\"Punic\", \"Sicily_Punic\", \"Phoen\"] # \"Sardinia\", \"Spain\" \"Algeria\", \n",
    "\n",
    "ind_modified=\"./eigenstrat/combined/punic.v49.0_ind.ind\"    # Where to save the modified version to\n",
    "\n",
    "modifiy_iid_files(df_ind, pops_overwrite=pops_overwrite, \n",
    "                  pops_overwrite12=pops_overwrite12,\n",
    "                  ind_modified = ind_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Split up Iberian Bronze Age and Sardinian Nuragic too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_overwrite = [\"Algeria_N\", \"Punic\", \"Italy_Sicily_Phoenician\",\n",
    "                  \"Sicily_IA_Polizzello\", \"Sicani\", \"Phoen\",\n",
    "                  \"Morocco_LN\", \"Punic_oAfrican\", \n",
    "                  \"Iberia_North_BA_Africa_all\", \"Iberia_BA\", \"Iberia_IA\",\n",
    "                  \"Iberia_Greek\", \"Iberia_Hellenistic\",\n",
    "                  \"Iberia_BellBeaker_o\", \"Gibraltar_N\", \n",
    "                  \"Iberia_Iberian\", \"Iberia_Celtiberian\", \"Iberia_Tartessian\",\n",
    "                  \"Italy_Sardinia_C_o\", \"Nuragic\",\n",
    "                  \"Nigeria_IA\", \"Nigeria_Medieval\"\n",
    "                  ]\n",
    "\n",
    "pops_overwrite12 = [[\"Morocco_LN\", \"Morocco_LN\"], [\"Morocco_EN\", \"Morocco_EN\"],\n",
    "                   [\"Morocco_Iberomaurusian\",\"Morocco_Iberomaurusian\"], [\"YRI\",\"YRI\"]]\n",
    "\n",
    "ind_modified=\"./eigenstrat/combined/punic.v49.0_ind1.ind\"    # Where to save the modified version to\n",
    "\n",
    "modifiy_iid_files(df_ind, pops_overwrite=pops_overwrite, \n",
    "                  pops_overwrite12=pops_overwrite12,\n",
    "                  ind_modified = ind_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Modify all targets for distal modelling (Punics and Proximal Sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_merged=\"./eigenstrat/combined/punic.v49.0.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")\n",
    "\n",
    "df_meta = pd.read_csv(\"/n/groups/reich/hringbauer/Data/v49.0.anno.csv\")\n",
    "dft = pd.merge(df_ind[\"iid\"], df_meta[[\"iid\", \"loc\", \"clst\", \"n_cov_snp\", \"age\", \"lat\", \"lon\"]], on=\"iid\")\n",
    "\n",
    "df_labels = pd.read_csv(\"./data/qpAdm_pops.tsv\", sep=\"\\t\")\n",
    "\n",
    "dfs = []\n",
    "for index, row in df_labels.iterrows():\n",
    "    dft1 = dft[dft[\"clst\"].str.contains(row[\"clst\"]) & (dft[\"loc\"] == row[\"loc\"])]\n",
    "    dfs.append(dft1)\n",
    "    \n",
    "df_targets = pd.concat(dfs)\n",
    "\n",
    "print(f\"Saving meta of {len(df_targets)} Individuals for further processing.\")\n",
    "#df_targets.to_csv(\"./output/tables/qpadm.targets.distal.v46.3.tsv\", sep=\"\\t\", index=False)\n",
    "iids = df_targets[\"iid\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only save if additional Individuals need a rerun\n",
    "df_temp = pd.read_csv(\"./output/tables/qpadm.targets.distal.v46.3.tsv\", sep=\"\\t\")\n",
    "idx = [iid not in df_temp[\"iid\"].values for iid in iids]\n",
    "#df_targets[idx].to_csv(\"./output/tables/qpadm.targets.distal.v46.3.add.tsv\", sep=\"\\t\")\n",
    "print(f\"Saved {np.sum(idx)} Indivdiuals for a rerun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_clst_to_iid(df_ind, iids, pops_overwrite12=[], \n",
    "                savepath=\"./eigenstrat/combined/punic.v46.3_ind2.ind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Modify Individual PCA clusters of Punic Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_merged=\"./eigenstrat/combined/punic.v49.0.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")\n",
    "\n",
    "### Modify the Clusters\n",
    "iids_afr_punic =  [\"I18193\", \"I18189\", \"I22093\"]  # \"I22113\" high but not high enough\n",
    "iids_afr_cline = [\"I21966\", \"I21984\", \"I22094\", \"I22090\", \"VIL011\", \"VIL006\", \"VIL009\", \"VIL010\", \"VIL007\"] # but not VIL004\n",
    "\n",
    "df_ind = set_iids_to_clst(df_ind, iids=iids_afr_cline, clst=\"PunicCline\", savepath=\"\")\n",
    "df_ind = set_iids_to_clst(df_ind, iids=iids_afr_punic, clst=\"PunicAfrican\", savepath=\"\")\n",
    "\n",
    "savepath=\"./eigenstrat/combined/punic.v49.0_punic_clst.ind\"\n",
    "#df_ind.to_csv(savepath, sep=\" \", index=None, header=False)\n",
    "print(f\"Saved {len(df_ind)} Individuals to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the additional individuals to final eigenstrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 144 additional Indivdiuals\n",
      "Saved modified 143 Table to: ./output/share/gronau.v49.2.add.ind.tsv\n"
     ]
    }
   ],
   "source": [
    "path_load = f\"./eigenstrat/anc_only.v{version}.ind\"   \n",
    "df_ind = pd.read_csv(path_load, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "\n",
    "df_add = pd.read_csv(\"./data/v49-added-samples.txt\", header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "df_add.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_add)} additional Indivdiuals\")\n",
    "\n",
    "df2 = pd.merge(df_ind[[\"iid\", \"clst\"]], df_add[[\"iid\", \"clst\"]], \n",
    "               on=\"iid\", suffixes=('_new', '_add'))\n",
    "\n",
    "### Save the table for manual review\n",
    "save_path = \"./output/share/gronau.v49.2.add.ind.tsv\"\n",
    "df2.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "print(f\"Saved modified {len(df2)} Table to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loading single Eigenstrat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>sex</th>\n",
       "      <th>clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I0626_all</td>\n",
       "      <td>M</td>\n",
       "      <td>Vietnam_N_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I0627_all</td>\n",
       "      <td>F</td>\n",
       "      <td>Vietnam_N_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I1137_all_published</td>\n",
       "      <td>M</td>\n",
       "      <td>Vietnam_N_all_published</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I1859_all</td>\n",
       "      <td>F</td>\n",
       "      <td>Vietnam_N_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I2497_all</td>\n",
       "      <td>F</td>\n",
       "      <td>Vietnam_BA_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25093</th>\n",
       "      <td>I30293.v49.1_d</td>\n",
       "      <td>F</td>\n",
       "      <td>Albania_BA_IA_1d.rel.I16256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25094</th>\n",
       "      <td>I30299.v49.1_d</td>\n",
       "      <td>M</td>\n",
       "      <td>Albania_BA_IA_1d.rel.I16256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25095</th>\n",
       "      <td>I30302.v49.1_d</td>\n",
       "      <td>F</td>\n",
       "      <td>Albania_BA_IA_1d.rel.I16256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25096</th>\n",
       "      <td>I30304.v49.1_d</td>\n",
       "      <td>U</td>\n",
       "      <td>Albania_BA_IA_1d.rel.I16256_lc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25097</th>\n",
       "      <td>I21391</td>\n",
       "      <td>F</td>\n",
       "      <td>England_N_Megalithic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25098 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       iid sex                            clst\n",
       "0                I0626_all   M                   Vietnam_N_all\n",
       "1                I0627_all   F                   Vietnam_N_all\n",
       "2      I1137_all_published   M         Vietnam_N_all_published\n",
       "3                I1859_all   F                   Vietnam_N_all\n",
       "4                I2497_all   F                  Vietnam_BA_all\n",
       "...                    ...  ..                             ...\n",
       "25093       I30293.v49.1_d   F     Albania_BA_IA_1d.rel.I16256\n",
       "25094       I30299.v49.1_d   M     Albania_BA_IA_1d.rel.I16256\n",
       "25095       I30302.v49.1_d   F     Albania_BA_IA_1d.rel.I16256\n",
       "25096       I30304.v49.1_d   U  Albania_BA_IA_1d.rel.I16256_lc\n",
       "25097               I21391   F            England_N_Megalithic\n",
       "\n",
       "[25098 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_load = f\"/n/groups/reich/DAVID/V{v0}/V{version}/v{version}.ind\"\n",
    "df_ind = pd.read_csv(path_load, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Phoen\")]\n",
    "\n",
    "#pops = [\"Spain_IA_Tartessian\", \"Spain_IA_Celt\", \"Italy_Sardinia_BA_Nuragic\", \n",
    "#        \"Italy_Sicily_IA_Sicani\", \"Greece_BA_Mycenaean\", \"Israel_Phoenician\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to David's Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(\"/n/groups/reich/hringbauer/Data/Unpublished_data.tsv\", sep=\"\\t\")\n",
    "age_col = \"Average of 95.4% date range in calBP (defined as 1950 CE)  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.str.contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_col = 'Group_ID (format convention which we try to adhere to is \"Country_<Geographic.Region_<Geographic.Subregion_>><Archaeological.Period.Or.DateBP_<Alternative.Archaeological.Period_>><Archaeological.Culture_<Alternative.Archaeological.Culture>><genetic.subgrouping.index.if.necessary_><\"o_\"sometimes.with.additional.detail.if.an.outlier><additional.suffix.especially.relative.status.if.we.recommend.removing.from.main.analysis.grouping><\"contam_\".if.contaminated><\"lc_\".if.<15000.SNPs.on.autosomal.targets><\".SG\".or.\".DG\".if.shotgun.data>; HG=hunter-gatherer, N=Neolithic, C=Chalcolithic/CopperAge, BA=BronzeAge, IA=IronAge, E=Early, M=Middle, L=Late, A=Antiquity)'\n",
    "groups = df_t[group_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsts_list = \"|\".join(clsts)\n",
    "idx = groups.str.contains(clsts_list)\n",
    "print(f\"Found {np.sum(idx)} Individuals\")\n",
    "df_found = df_t[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_found[150:174][[\"Master ID\", group_col, \"Publication\", \"Locality\", age_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fto_csvo_csv(\"./output/tables/samples_claim.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Entries in Eigenstrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1320 Individuals\n"
     ]
    }
   ],
   "source": [
    "#ind_merged=\"./eigenstrat/anc_only.v46.3.ind\"          # What .ind to load\n",
    "ind_merged=\"./eigenstrat/combined/punic.v49.2.ind\"          # What .ind to load\n",
    "df_ind = pd.read_csv(ind_merged, delim_whitespace=True, header=None)\n",
    "df_ind.columns=[\"iid\", \"sex\", \"clst\"]\n",
    "print(f\"Loaded {len(df_ind)} Individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "include    147\n",
       "Name: clst, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"include\")][\"clst\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Outgroup: \n",
    "### Israel_MLBA Italy_Sardinia_EBA Spain_LBA Italy_Sicily_EBA Steppe_MLBA Greece_Minoan_Lassithi\n",
    "### Additional Source: Spain_IA I12433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[\"clst\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind[df_ind[\"clst\"].str.contains(\"Algeria\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
