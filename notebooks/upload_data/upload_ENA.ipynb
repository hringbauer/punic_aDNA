{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0265cab1-f263-4c90-9dea-c8b00a55af65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-a-17-125.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/punic_aDNA\n",
      "CPU Count: 32\n",
      "3.8.12 (default, Sep 13 2021, 17:05:27) \n",
      "[GCC 9.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os  # For Saving to Folder\n",
    "import pandas as pd\n",
    "import socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import itertools as it\n",
    "from hashlib import md5\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/punic_aDNA/\"  # The Path on Midway Cluster\n",
    "else:\n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "# Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d71982a7-92b0-4d3e-bbe5-e370ba20de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_paths_exist(path_list):\n",
    "    \"\"\"Check whether paths exist.\n",
    "    Print non existing ones.\"\"\"\n",
    "    m = False\n",
    "    for p in path_list:\n",
    "        if not os.path.exists(p):\n",
    "            print(p)\n",
    "            m = True\n",
    "    if ~m:\n",
    "        print(f\"All {len(path_list)} Files found.\")\n",
    "\n",
    "def get_md5(fname):\n",
    "    \"\"\"Return md5 hash of file at path fname\"\"\"\n",
    "    hash_md5 = md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7e425-4ee3-4619-8b8b-4f67cbc11ac9",
   "metadata": {},
   "source": [
    "# 1) Load Table of Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0603fbf7-10eb-4da3-b2d1-f59b1cb7b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded table of 210 iids to upload.\n",
      "Loaded meta table of 48014 iids to upload.\n",
      "Found all Target Genetic IDs in Meta Table\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/n/groups/reich/hringbauer/git/punic_aDNA/data/final_new_genomes210.v56.3.tsv\", sep=\"\\t\")\n",
    "print(f\"Loaded table of {len(df)} iids to upload.\")\n",
    "\n",
    "### Load Meta File\n",
    "anno_path = \"/n/groups/reich/DAVID/V56/V56.3/v56.3_HO_all.anno\"\n",
    "df_meta = pd.read_csv(anno_path, sep='\\t', low_memory=False)\n",
    "print(f\"Loaded meta table of {len(df_meta)} iids to upload.\")\n",
    "\n",
    "### Find Genetic IDs in meta file that are in target\n",
    "df1 = df_meta[df_meta[\"Genetic ID\"].isin(df[\"Genetic ID\"])]\n",
    "assert(len(df1)==len(df))\n",
    "print(\"Found all Target Genetic IDs in Meta Table\")\n",
    "\n",
    "## Print Genetic IDs not matchable to meta file\n",
    "#df[~df[\"Genetic ID\"].isin(df_meta[\"Genetic ID\"])] \n",
    "\n",
    "### prepare Subtables\n",
    "df1_paths = df1[[\"Genetic ID\", \"Master ID\", \"Data mtDNA bam\", \"Data autosomal bam\"]].copy() #\"Data mtDNA fasta\"\n",
    "df2_paths = df1_paths.copy() # For mtDNA .bam list\n",
    "df_missing_mtDNA = df1_paths[df1_paths[\"Data mtDNA bam\"]==\"..\"]\n",
    "\n",
    "assert(len(df1_paths) == len(list(set(df1_paths[\"Data autosomal bam\"])))) # Sanity check for duplicate bam paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d5016-27f4-45bc-9f54-7468403f1ce8",
   "metadata": {},
   "source": [
    "### [Optional]: Browse Meta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa9356-1570-40b4-9c4b-2171eadddc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df1.columns:\n",
    "    print(c)\n",
    "#df1_paths[\"Data mtDNA bam\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cf9009-3f13-43b9-91e5-72dfdb2ef85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_paths_exist(df1_paths[\"Data autosomal bam\"])\n",
    "#check_paths_exist(df1_paths[\"Data mtDNA bam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc805176-2ada-49d2-9121-0d7de39d284a",
   "metadata": {},
   "source": [
    "### [Optional]: Save paths for IT team review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54f7bdb1-fd80-4279-a55b-bd10dcfe0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_paths.to_csv(\"/n/groups/reich/hringbauer/git/punic_aDNA/output/share/path_bams.tsv\", sep=\"\\t\", index=False)\n",
    "df_missing_mtDNA.to_csv(\"/n/groups/reich/hringbauer/git/punic_aDNA/output/share/path_bams_missing_mtDNA_path.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7dcc0fa4-7da3-49bc-b5ba-35d3169ab72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_missing_mtDNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b285243-e763-4b76-b11b-999db262590a",
   "metadata": {},
   "source": [
    "# 2) Extract Relevant Entries for ENA upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d41f3-3bd9-42ff-9b3a-1c4f57481603",
   "metadata": {},
   "source": [
    "## 2a) Prepare Sample .tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3f38dc5-31c2-4f11-8689-34dcfb74f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df1[[\"Genetic ID\", \"Master ID\", \"Group ID\", \"Locality\", \"Political Entity\", \"Lat.\", \"Long.\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fefb87f-9867-45f3-b4bf-19704c943ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv(\"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/sample_list_punic.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1482a-ea96-4cd9-91a2-833f275c874e",
   "metadata": {},
   "source": [
    "## 2b) Prepare autosomal .bam path .tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5141b4e6-356b-4b6b-99d6-996411f90fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse out file name\n",
    "#df1_paths[\"file_name\"] = df1_paths[\"Data autosomal bam\"].str.split(\"/\").str[-1]\n",
    "\n",
    "df1_paths[\"file_name\"] = df1_paths[\"Master ID\"] + \".bam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557f6de-6f1e-4966-a6c5-c4eccc6fa342",
   "metadata": {},
   "source": [
    "## Soft Link into upload folder\n",
    "Takes only few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90da8883-6242-4aee-adfe-2e3f1400ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_folder = \"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_autosomal/\"\n",
    "\n",
    "for p,f in df1_paths[[\"Data autosomal bam\", \"file_name\"]].values:\n",
    "    path_t = os.path.join(upload_folder, f)\n",
    "    c = f\"ln -s {p} {path_t}\"\n",
    "    os.system(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79602b-e655-4183-b9cf-06282a57346b",
   "metadata": {},
   "source": [
    "### Create MD5Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75756d-8aac-4338-88ee-4fefc6fc56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "upload_folder = \"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_autosomal/\"\n",
    "\n",
    "m5s = []\n",
    "for f in df1_paths[\"file_name\"].values:\n",
    "    path_t = os.path.join(upload_folder, f)\n",
    "    print(f\"Getting MD5 of {path_t}...\")\n",
    "    m5 = get_md5(path_t)\n",
    "    m5s.append(m5)\n",
    "    \n",
    "df1_paths[\"file_md5\"] = m5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b89955e8-f7dd-4600-bdca-e8d1f94ce7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table of n=210 autosomal bams to: /n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_autosomal_list_punic.tsv\n"
     ]
    }
   ],
   "source": [
    "savepath = \"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_autosomal_list_punic.tsv\"\n",
    "df1_paths.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "print(f\"Saved table of n={len(df1_paths)} autosomal bams to: {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dae60-ef22-4f30-ae2c-e82d73262c88",
   "metadata": {},
   "source": [
    "## 2c) Prepare mtDNA .bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60c76ce0-0915-4ac1-95dc-fd8beca314c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 missing mtDNA bams\n"
     ]
    }
   ],
   "source": [
    "idx_miss = df2_paths[\"Data mtDNA bam\"] == \"..\" # Save idx of missing mtDNA bams\n",
    "df2m = df2_paths[idx_miss].copy() # Subset to missing table\n",
    "print(f\"Found {len(df2m)} missing mtDNA bams\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5b09c0f6-6159-4785-81dc-4dc7d9ba4e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 from Matt's bam paths\n"
     ]
    }
   ],
   "source": [
    "### Get Index of where matt pipeline\n",
    "idx2 = df2m[\"Data autosomal bam\"].str.contains(\"/n/groups/reich/matt/pipeline/\")\n",
    "print(f\"{np.sum(idx2)}/{len(idx2)} from Matt's bam paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "41593bdc-f04a-4b7a-b4af-679e9b0e679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Matt's bam paths - just replace hg19 with rsrs for mtDNA bam\n",
    "df2m[\"Data mtDNA bam\"] = df2m[\"Data autosomal bam\"].str.replace(\"hg19\", \"rsrs\").values\n",
    "\n",
    "### Fix the one remaining case manually:\n",
    "df2m.loc[~idx2, \"Data mtDNA bam\"] = \"/n/data1/hms/genetics/reich/1000Genomes/amh_samples/ancientMergeSets__MT/C-per_sample_versions/I8577/MT.v0002.0__2018_03_08/merged/aln.sort.mapped.rmdupse_adna_v2.md.bam\"\n",
    "\n",
    "### Copy back to full dataframe\n",
    "df2_paths[idx_miss] = df2m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6175a-c952-4d55-ba7c-db68d9578543",
   "metadata": {},
   "source": [
    "### Check whether all mtDNA bam paths exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5e2b0ff-9c86-4d5c-920f-80b67fb04ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 210 Files found.\n"
     ]
    }
   ],
   "source": [
    "check_paths_exist(df2_paths[\"Data mtDNA bam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f51252-ef75-4af7-a91c-cf0d5db22b25",
   "metadata": {},
   "source": [
    "## 2c1) Prepare full MT bam table for ENA upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a9f9dca0-448b-4532-b871-e48d904347d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_folder = \"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_mtDNA/\"\n",
    "\n",
    "df2_paths[\"file_name\"] = df2_paths[\"Master ID\"] + \".MT.bam\"\n",
    "\n",
    "for p,f in df2_paths[[\"Data mtDNA bam\", \"file_name\"]].values:\n",
    "    path_t = os.path.join(upload_folder, f)\n",
    "    c = f\"ln -s {p} {path_t}\"\n",
    "    os.system(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef3f76-945a-4add-b22e-df4b17f61bcf",
   "metadata": {},
   "source": [
    "### Create m5 Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249f895-59bd-4f4b-ab1f-f06084701c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "upload_folder = \"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_mtDNA/\"\n",
    "\n",
    "m5s = []\n",
    "for f in df2_paths[\"file_name\"].values:\n",
    "    path_t = os.path.join(upload_folder, f)\n",
    "    print(f\"Getting MD5 of {path_t}...\")\n",
    "    m5 = get_md5(path_t)\n",
    "    m5s.append(m5)\n",
    "    \n",
    "df2_paths[\"file_md5\"] = m5s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38619126-ce80-418e-805d-fa69217e1241",
   "metadata": {},
   "source": [
    "## Save complete MT bam table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "691b6c1e-9c5c-41e6-b837-852247d5db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table of n=210 autosomal bams to: /n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_MT_list_punic.tsv\n"
     ]
    }
   ],
   "source": [
    "savepath = \"/n/groups/reich/hringbauer/git/punic_aDNA/output/release/bam_MT_list_punic.tsv\"\n",
    "df2_paths.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "print(f\"Saved table of n={len(df2_paths)} autosomal bams to: {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e588cb-c343-46da-a238-fd1c18454670",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96f6dc-6534-4e57-89d9-d7ebabb7a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df1.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44509e7c-5033-49e1-9a88-59c22727bbfd",
   "metadata": {},
   "source": [
    "## Explore Iosif Tables for ENA upload\n",
    "Better done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3042773c-a407-4d1f-9c5a-1823315808fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ibams = \"/n/groups/reich/iosif/SteppeEneolithic/V10a/TOPUBLISH/BAM/IE_BAMs.tsv\"\n",
    "path_isamples = \"/n/groups/reich/iosif/SteppeEneolithic/V10a/TOPUBLISH/BAM/IE_Samples.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed395df-19c9-45f2-b3cf-c70779d673d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded table of 708\n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv(path_ibams, sep=\"\\t\")\n",
    "print(f\"Loaded table of {len(dft)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0035bf-6636-4ec4-ad4f-0519959ca2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded table of 356\n"
     ]
    }
   ],
   "source": [
    "dft2 = pd.read_csv(path_isamples, sep=\"\\t\")\n",
    "print(f\"Loaded table of {len(dft)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410856b-b86b-4710-9fc4-3f303fe3f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368c6495-6b3a-4178-b5a5-542d8343e0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_alias\n",
       "I26224_IE       2\n",
       "I32864_IE       2\n",
       "I6729_IE        2\n",
       "I6728_IE        2\n",
       "I6727_IE        2\n",
       "               ..\n",
       "I6068_IE        2\n",
       "I6066_IE        2\n",
       "I6065_IE        2\n",
       "I6064_IE        2\n",
       "I6559_IE_new    2\n",
       "Name: count, Length: 354, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[\"sample_alias\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b2bdb6-0cb5-448d-9c39-f8f374facdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>sample_alias</th>\n",
       "      <th>instrument_model</th>\n",
       "      <th>library_name</th>\n",
       "      <th>library_source</th>\n",
       "      <th>library_selection</th>\n",
       "      <th>library_strategy</th>\n",
       "      <th>library_layout</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_md5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRJEB81467</td>\n",
       "      <td>I26224_IE</td>\n",
       "      <td>Illumina NextSeq 500</td>\n",
       "      <td>I26224_IE</td>\n",
       "      <td>GENOMIC</td>\n",
       "      <td>Hybrid Selection</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>I26224.bam</td>\n",
       "      <td>118b7625e3c9d917bcece0d4687f5708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>PRJEB81467</td>\n",
       "      <td>I26224_IE</td>\n",
       "      <td>Illumina NextSeq 500</td>\n",
       "      <td>I26224.MT</td>\n",
       "      <td>GENOMIC</td>\n",
       "      <td>Hybrid Selection</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>I26224.MT.bam</td>\n",
       "      <td>8166e24de5b7673cf666c8c5bd2c5ed5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          study sample_alias      instrument_model library_name  \\\n",
       "0    PRJEB81467    I26224_IE  Illumina NextSeq 500    I26224_IE   \n",
       "354  PRJEB81467    I26224_IE  Illumina NextSeq 500    I26224.MT   \n",
       "\n",
       "    library_source library_selection library_strategy library_layout  \\\n",
       "0          GENOMIC  Hybrid Selection            OTHER         SINGLE   \n",
       "354        GENOMIC  Hybrid Selection            OTHER         SINGLE   \n",
       "\n",
       "         file_name                          file_md5  \n",
       "0       I26224.bam  118b7625e3c9d917bcece0d4687f5708  \n",
       "354  I26224.MT.bam  8166e24de5b7673cf666c8c5bd2c5ed5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[dft[\"sample_alias\"]==\"I26224_IE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ef42b-db4d-457c-920f-6708e2cbd72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
